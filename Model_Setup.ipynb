{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n",
      "Pysteps configuration file found at: /scratch/mch/fackerma/miniforge3/envs/testenv/lib/python3.12/site-packages/pysteps/pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pyart\n",
    "import glob\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "from pyproj import Transformer\n",
    "import radlib\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import xmltodict, geopandas, geojson, xml, json #xml and json do not exist\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import geopy.distance\n",
    "import numpy.matlib as npm\n",
    "import copy\n",
    "from scipy.signal import convolve2d\n",
    "from astropy.convolution import convolve\n",
    "import scipy.ndimage as ndi\n",
    "import re\n",
    "from skimage.draw import polygon\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from pysteps import io, motion, rcparams\n",
    "from pysteps.utils import conversion, transformation\n",
    "from pysteps.visualization import plot_precip_field, quiver\n",
    "\n",
    "import json\n",
    "\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "import datetime\n",
    "\n",
    "\n",
    "os.environ[\"library_metranet_path\"] = \"/store_new/mch/msrad/idl/lib/radlib4/\" # needed for pyradlib\n",
    "os.environ[\"METRANETLIB_PATH\"] = \"/store_new/mch/msrad/idl/lib/radlib4/\" # needed for pyart_mch\n",
    "\n",
    "\n",
    "# Calculate Swiss grid coordinates into composite raster points\n",
    "def swiss_to_grid_index(swiss_x, swiss_y, clons, clats, zh_shape):\n",
    "    # Initialize transformers\n",
    "    transformer_swiss_to_3035 = Transformer.from_crs(21781, 3035, always_xy=True)\n",
    "    \n",
    "    # Transform Swiss coordinates to EPSG:3035\n",
    "    x_3035, y_3035 = transformer_swiss_to_3035.transform(swiss_x, swiss_y)\n",
    "    \n",
    "    # Calculate distances\n",
    "    distances = np.sqrt((clons - x_3035)**2 + (clats - y_3035)**2)\n",
    "    \n",
    "    # Find the index of the minimum distance\n",
    "    y_idx, x_idx = np.unravel_index(np.argmin(distances), distances.shape)\n",
    "    \n",
    "    # Create a function to get values at specific vertical levels\n",
    "    def get_value_at_level(zh_array, level):\n",
    "        if 0 <= level < zh_shape[2]:\n",
    "            return zh_array[y_idx, x_idx, level]\n",
    "        else:\n",
    "            raise ValueError(f\"Level must be between 0 and {zh_shape[2]-1}\")\n",
    "    \n",
    "    return y_idx, x_idx, get_value_at_level\n",
    "\n",
    "# Function to retrieve cross sections for all variables of the wind composite\n",
    "def load_and_create_cross_sections(year, month, day, valid_time):\n",
    "    # Load the .npz file\n",
    "    data = np.load(f'/scratch/mch/fackerma/orders/full_composite_npz/{year}{month}{day}{valid_time}00_conv_wind_composite_data.npz')\n",
    "    \n",
    "    # Access the specific arrays\n",
    "    ZH = data['ZH_max']\n",
    "    rad_shear = data['RAD_SHEAR_LLSD_max']\n",
    "    az_shear = data['AZ_SHEAR_LLSD_abs_max']\n",
    "    RVEL = data['RVEL_DE_abs_max']\n",
    "    KDP = data['KDP_max']\n",
    "    ZDR = data['ZH_max']\n",
    "    \n",
    "    # Create cross-sections and 2D projections for each array\n",
    "    arrays = [ZH, rad_shear, az_shear, RVEL, KDP, ZDR]\n",
    "    names = ['ZH', 'rad_shear', 'az_shear', 'RVEL', 'KDP', 'ZDR']\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for arr, name in zip(arrays, names):\n",
    "        # Create cross-sections\n",
    "        results[f'{name}_x_cross'] = arr[y_idx, x_start:x_end, :]\n",
    "        results[f'{name}_y_cross'] = arr[y_start:y_end, x_idx, :]\n",
    "        \n",
    "        # Create 2D max projection\n",
    "        results[f'{name}_2d'] = np.nanmax(arr, axis=2)\n",
    "    \n",
    "    return results\n",
    "# All results are stored in a dictionary, with keys formatted as '{name}_x_cross', '{name}_y_cross', and '{name}_2d'\n",
    "\n",
    "\n",
    "# Define the Swiss grid (adjusted to match data dimensions)\n",
    "chx = np.arange(255000, 255000 + 710 * 1000, 1000)  # Easting values (710 points)\n",
    "chy = sorted(np.arange(-160000, -160000 + 640 * 1000, 1000), reverse=True)  # Northing values (640 points)\n",
    "X, Y = np.meshgrid(chx, chy)\n",
    "\n",
    "# Initialize transformer for Swiss grid to WGS84 (EPSG:21781 to EPSG:4326 PlateCarree)\n",
    "transformer = Transformer.from_crs(21781, 4326, always_xy=True)\n",
    "clons, clats = transformer.transform(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRT_2019_05-10.pkl...\n",
      "Loading TRT_2020_05-10.pkl...\n",
      "Loading TRT_2021_05-10.pkl...\n",
      "Loading TRT_2022_05-10.pkl...\n",
      "Loading TRT_2023_05-10.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mch/fackerma/miniforge3/envs/testenv/lib/python3.12/site-packages/geopandas/array.py:1638: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as WGS 84 (the single non-null crs provided).\n",
      "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataframe shape: (2240266, 91)\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directory and file names\n",
    "base_dir = \"/scratch/mch/fackerma/orders/TRT_processing_2/\"\n",
    "yearly_files = [\n",
    "    \"TRT_2019_05-10.pkl\",\n",
    "    \"TRT_2020_05-10.pkl\",\n",
    "    \"TRT_2021_05-10.pkl\",\n",
    "    \"TRT_2022_05-10.pkl\",\n",
    "    \"TRT_2023_05-10.pkl\",\n",
    "]\n",
    "\n",
    "# Load and merge dataframes\n",
    "dfs = []\n",
    "for file_name in yearly_files:\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading {file_name}...\")\n",
    "        df = pd.read_pickle(file_path)\n",
    "        dfs.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ File not found: {file_name}\")\n",
    "\n",
    "if not dfs:\n",
    "    print(\"No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nMerged dataframe shape: {merged_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "                timestamp                                           geometry  \\\n",
      "65824 2019-06-15 15:40:00  POLYGON ((8.4515 45.9795, 8.4514 45.9705, 8.43...   \n",
      "65825 2019-06-15 15:40:00  POLYGON ((7.3669 46.6047, 7.3669 46.5777, 7.35...   \n",
      "65826 2019-06-15 15:40:00  POLYGON ((7.6538 46.5596, 7.6277 46.5416, 7.60...   \n",
      "65827 2019-06-15 15:40:00  POLYGON ((8.356 46.4391, 8.3559 46.4301, 8.342...   \n",
      "65828 2019-06-15 15:40:00  POLYGON ((8.1463 46.3237, 8.1201 46.3059, 8.11...   \n",
      "65829 2019-06-15 15:40:00  POLYGON ((8.0921 46.1351, 8.0919 46.1171, 8.07...   \n",
      "65830 2019-06-15 15:40:00  POLYGON ((8.1563 46.0987, 8.1562 46.0897, 8.14...   \n",
      "65831 2019-06-15 15:40:00  POLYGON ((6.6971 45.9546, 6.6975 45.9187, 6.71...   \n",
      "65832 2019-06-15 15:40:00  POLYGON ((5.2968 44.4882, 5.2845 44.479, 5.259...   \n",
      "65833 2019-06-15 15:40:00  POLYGON ((7.947 45.839, 7.934 45.8301, 7.9212 ...   \n",
      "65834 2019-06-15 15:40:00  POLYGON ((7.4965 45.8041, 7.4965 45.7862, 7.53...   \n",
      "65835 2019-06-15 15:40:00  POLYGON ((7.0598 45.7226, 7.047 45.7135, 7.034...   \n",
      "65836 2019-06-15 15:40:00  POLYGON ((7.5476 45.6242, 7.5348 45.6152, 7.53...   \n",
      "65837 2019-06-15 15:40:00  POLYGON ((7.1519 45.3001, 7.1519 45.2911, 7.13...   \n",
      "65838 2019-06-15 15:40:00  POLYGON ((5.9222 44.5886, 5.9099 44.5794, 5.91...   \n",
      "65839 2019-06-15 15:40:00  POLYGON ((6.2567 46.6346, 6.2585 46.5537, 6.32...   \n",
      "65840 2019-06-15 15:40:00  POLYGON ((6.8168 44.4894, 6.767 44.4531, 6.767...   \n",
      "65841 2019-06-15 15:40:00  POLYGON ((6.9165 45.9379, 6.9166 45.9289, 6.90...   \n",
      "65842 2019-06-15 15:40:00  POLYGON ((11.2434 46.5861, 11.2298 46.5776, 11...   \n",
      "65843 2019-06-15 15:40:00  POLYGON ((6.1824 44.7717, 6.17 44.7626, 6.1702...   \n",
      "65844 2019-06-15 15:40:00  POLYGON ((7.7998 46.937, 7.7997 46.919, 7.7865...   \n",
      "65845 2019-06-15 15:40:00  POLYGON ((11.7645 46.7296, 11.7609 46.6847, 11...   \n",
      "65846 2019-06-15 15:40:00  POLYGON ((6.5561 46.7003, 6.5431 46.6912, 6.53...   \n",
      "65847 2019-06-15 15:40:00  POLYGON ((6.8599 46.4144, 6.8469 46.4053, 6.80...   \n",
      "65848 2019-06-15 15:40:00  POLYGON ((7.0162 46.3791, 7.0163 46.3611, 7.02...   \n",
      "65849 2019-06-15 15:40:00  POLYGON ((7.0805 46.4873, 7.0806 46.4693, 7.06...   \n",
      "65850 2019-06-15 15:40:00  POLYGON ((7.0304 46.2262, 7.0304 46.2172, 7.01...   \n",
      "65851 2019-06-15 15:40:00  POLYGON ((7.0828 46.1364, 7.0828 46.1274, 7.07...   \n",
      "65852 2019-06-15 15:40:00  POLYGON ((6.2066 46.5441, 6.2068 46.5351, 6.18...   \n",
      "65853 2019-06-15 15:40:00  POLYGON ((5.9135 46.7655, 5.9137 46.7565, 5.88...   \n",
      "65854 2019-06-15 15:40:00  POLYGON ((6.3754 45.9161, 6.3626 45.907, 6.362...   \n",
      "65855 2019-06-15 15:40:00  POLYGON ((5.4583 47.7482, 5.4453 47.739, 5.445...   \n",
      "65856 2019-06-15 15:40:00  POLYGON ((5.2639 47.6098, 5.2643 47.6008, 5.25...   \n",
      "65857 2019-06-15 15:40:00  POLYGON ((5.4252 47.5677, 5.4122 47.5585, 5.41...   \n",
      "65858 2019-06-15 15:40:00  POLYGON ((7.5782 47.5671, 7.5649 47.5581, 7.52...   \n",
      "65859 2019-06-15 15:40:00  POLYGON ((11.0253 47.4306, 10.9976 47.4135, 10...   \n",
      "65860 2019-06-15 15:40:00  POLYGON ((10.3766 47.2149, 10.3736 47.161, 10....   \n",
      "65861 2019-06-15 15:40:00  POLYGON ((6.2991 46.4821, 6.2863 46.473, 6.208...   \n",
      "65862 2019-06-15 15:40:00  POLYGON ((8.0524 47.2058, 8.0523 47.1968, 8.03...   \n",
      "\n",
      "      CS Marker STA Marker ESWD Marker Gust_Flag             traj_ID  \\\n",
      "65824         0          0           0         -  2019061515350113.0   \n",
      "65825         0          0           0         -  2019061514550083.0   \n",
      "65826         0          0           0         -  2019061515300099.0   \n",
      "65827         0          0           0         -  2019061515350107.0   \n",
      "65828         0          0           0         -  2019061515200086.0   \n",
      "65829         0          0           0         -  2019061515250100.0   \n",
      "65830         0          0           0         -  2019061515200090.0   \n",
      "65831         0          0           0         -  2019061515400112.0   \n",
      "65832         0          0           0         -  2019061515000118.0   \n",
      "65833         0          0           0         -  2019061515400114.0   \n",
      "65834         0          0           0         -  2019061515350120.0   \n",
      "65835         0          0           0         -  2019061515400117.0   \n",
      "65836         0          0           0         -  2019061514500089.0   \n",
      "65837         0          0           0         -  2019061515200111.0   \n",
      "65838         0          0           0         -  2019061515250121.0   \n",
      "65839         0          0           0         -  2019061515400098.0   \n",
      "65840         0          0           0         -  2019061515300126.0   \n",
      "65841         0          0           0         -  2019061515350117.0   \n",
      "65842         0          0           0         -  2019061515400097.0   \n",
      "65843         0          0           0         -  2019061515400125.0   \n",
      "65844         0          0           0         -  2019061513550078.0   \n",
      "65845         0          0           0         -  2019061515250090.0   \n",
      "65846         0          2           0       Yes  2019061509450011.0   \n",
      "65847         0          2           0       Yes  2019061515400005.0   \n",
      "65848         0          0           0         -  2019061515350046.0   \n",
      "65849         0          0           0         -  2019061515400017.0   \n",
      "65850         0          0           0         -  2019061510350021.0   \n",
      "65851         0          0           0         -  2019061515400044.0   \n",
      "65852         0          0           0         -  2019061515400062.0   \n",
      "65853         0          0           0         -  2019061515250030.0   \n",
      "65854         0          0           0         -  2019061515150101.0   \n",
      "65855         0          0           0         -  2019061515350087.0   \n",
      "65856         0          0           0         -  2019061515400087.0   \n",
      "65857         0          0           0         -  2019061515200068.0   \n",
      "65858         0          0           0         -  2019061514350064.0   \n",
      "65859         0          0           0         -  2019061515300087.0   \n",
      "65860         0          0           0         -  2019061515350094.0   \n",
      "65861         0          0           0         -  2019061515300036.0   \n",
      "65862         0          0           0         -  2019061512350048.0   \n",
      "\n",
      "               time      lon      lat  ... nrPOHthr010 nrPOHthr020  \\\n",
      "65824  2.019062e+11    8.466  45.9344  ...         NaN         NaN   \n",
      "65825  2.019062e+11   7.3255  46.4688  ...         NaN         NaN   \n",
      "65826  2.019062e+11    7.625  46.4964  ...         NaN         NaN   \n",
      "65827  2.019062e+11   8.2978  46.3686  ...         NaN         NaN   \n",
      "65828  2.019062e+11   8.1596  46.2682  ...         NaN         NaN   \n",
      "65829  2.019062e+11   8.0864  46.0837  ...         NaN         NaN   \n",
      "65830  2.019062e+11   8.1626  46.0558  ...         NaN         NaN   \n",
      "65831  2.019062e+11   6.7472  45.9162  ...         NaN         NaN   \n",
      "65832  2.019062e+11   5.2911   44.433  ...         NaN         NaN   \n",
      "65833  2.019062e+11   7.9403  45.8064  ...         NaN         NaN   \n",
      "65834  2.019062e+11   7.5858  45.7375  ...         NaN         NaN   \n",
      "65835  2.019062e+11    7.031  45.6781  ...         NaN         NaN   \n",
      "65836  2.019062e+11   7.4923   45.509  ...         NaN         NaN   \n",
      "65837  2.019062e+11   7.1679  45.1895  ...         NaN         NaN   \n",
      "65838  2.019062e+11   5.9731  44.5562  ...         NaN         NaN   \n",
      "65839  2.019062e+11   6.2876  46.5829  ...         NaN         NaN   \n",
      "65840  2.019062e+11   6.8395  44.4432  ...         NaN         NaN   \n",
      "65841  2.019062e+11   6.9936  45.8217  ...         NaN         NaN   \n",
      "65842  2.019062e+11  11.2773  46.5538  ...         NaN         NaN   \n",
      "65843  2.019062e+11   6.2233  44.7462  ...         NaN         NaN   \n",
      "65844  2.019062e+11   7.8107  46.8501  ...         NaN         NaN   \n",
      "65845  2.019062e+11  11.8004  46.7035  ...         NaN         NaN   \n",
      "65846  2.019062e+11   6.6665  46.5914  ...         NaN         NaN   \n",
      "65847  2.019062e+11   6.8981  46.3725  ...         NaN         NaN   \n",
      "65848  2.019062e+11   7.0244  46.3047  ...         NaN         NaN   \n",
      "65849  2.019062e+11   7.0945  46.4452  ...         NaN         NaN   \n",
      "65850  2.019062e+11   7.0534  46.1761  ...         NaN         NaN   \n",
      "65851  2.019062e+11   7.0839   46.069  ...         NaN         NaN   \n",
      "65852  2.019062e+11   6.2265  46.5056  ...         NaN         NaN   \n",
      "65853  2.019062e+11   6.0765  46.4329  ...         NaN         NaN   \n",
      "65854  2.019062e+11   6.4201  45.8526  ...         NaN         NaN   \n",
      "65855  2.019062e+11   5.4591  47.6737  ...         NaN         NaN   \n",
      "65856  2.019062e+11   5.2589  47.5496  ...         NaN         NaN   \n",
      "65857  2.019062e+11   5.4381  47.4581  ...         NaN         NaN   \n",
      "65858  2.019062e+11   7.5448  47.5093  ...         NaN         NaN   \n",
      "65859  2.019062e+11  11.0146   47.395  ...         NaN         NaN   \n",
      "65860  2.019062e+11  10.4108  47.1862  ...         NaN         NaN   \n",
      "65861  2.019062e+11   6.2801  46.4461  ...         NaN         NaN   \n",
      "65862  2.019062e+11    8.002  47.0655  ...         NaN         NaN   \n",
      "\n",
      "      nrPOHthr030 nrPOHthr040 nrPOHthr050 nrPOHthr060 nrPOHthr070 nrPOHthr080  \\\n",
      "65824         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65825         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65826         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65827         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65828         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65829         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65830         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65831         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65832         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65833         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65834         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65835         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65836         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65837         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65838         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65839         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65840         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65841         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65842         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65843         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65844         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65845         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65846         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65847         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65848         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65849         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65850         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65851         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65852         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65853         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65854         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65855         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65856         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65857         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65858         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65859         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65860         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65861         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "65862         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "      nrPOHthr090 nrPOHthr100  \n",
      "65824         NaN         NaN  \n",
      "65825         NaN         NaN  \n",
      "65826         NaN         NaN  \n",
      "65827         NaN         NaN  \n",
      "65828         NaN         NaN  \n",
      "65829         NaN         NaN  \n",
      "65830         NaN         NaN  \n",
      "65831         NaN         NaN  \n",
      "65832         NaN         NaN  \n",
      "65833         NaN         NaN  \n",
      "65834         NaN         NaN  \n",
      "65835         NaN         NaN  \n",
      "65836         NaN         NaN  \n",
      "65837         NaN         NaN  \n",
      "65838         NaN         NaN  \n",
      "65839         NaN         NaN  \n",
      "65840         NaN         NaN  \n",
      "65841         NaN         NaN  \n",
      "65842         NaN         NaN  \n",
      "65843         NaN         NaN  \n",
      "65844         NaN         NaN  \n",
      "65845         NaN         NaN  \n",
      "65846         NaN         NaN  \n",
      "65847         NaN         NaN  \n",
      "65848         NaN         NaN  \n",
      "65849         NaN         NaN  \n",
      "65850         NaN         NaN  \n",
      "65851         NaN         NaN  \n",
      "65852         NaN         NaN  \n",
      "65853         NaN         NaN  \n",
      "65854         NaN         NaN  \n",
      "65855         NaN         NaN  \n",
      "65856         NaN         NaN  \n",
      "65857         NaN         NaN  \n",
      "65858         NaN         NaN  \n",
      "65859         NaN         NaN  \n",
      "65860         NaN         NaN  \n",
      "65861         NaN         NaN  \n",
      "65862         NaN         NaN  \n",
      "\n",
      "[39 rows x 91 columns]\n",
      "\n",
      "Loaded Arrays:\n",
      "ZH: (640, 710, 93)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the Swiss grid (adjusted to match data dimensions)\n",
    "chx = np.arange(255000, 255000 + 710 * 1000, 1000)  # Easting values (710 points)\n",
    "chy = sorted(np.arange(-160000, -160000 + 640 * 1000, 1000), reverse=True)  # Northing values (640 points)\n",
    "X, Y = np.meshgrid(chx, chy)\n",
    "\n",
    "# Initialize transformer for Swiss grid to WGS84 (EPSG:21781 to EPSG:4326 PlateCarree)\n",
    "transformer = Transformer.from_crs(21781, 4326, always_xy=True)\n",
    "clons, clats = transformer.transform(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "def filter_rows_by_datetime(merged_df, datetime_str):\n",
    "    # Ensure the 'timestamp' column is in datetime format\n",
    "    merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'])\n",
    "    \n",
    "    # Convert input datetime string to a datetime object\n",
    "    target_datetime = pd.to_datetime(datetime_str)\n",
    "    \n",
    "    # Filter rows for the exact datetime\n",
    "    filtered_df = merged_df[merged_df['timestamp'] == target_datetime]\n",
    "    return filtered_df\n",
    "\n",
    "def load_npz_file(datetime_obj):\n",
    "    # Extract components from datetime\n",
    "    year = datetime_obj.strftime('%Y')\n",
    "    month = datetime_obj.strftime('%m')\n",
    "    day = datetime_obj.strftime('%d')\n",
    "    valid_time = datetime_obj.strftime('%H%M')  # Format: '1535' for 15:35\n",
    "    \n",
    "    # Load .npz file\n",
    "    file_path = f'/scratch/mch/maregger/hailclass/convective_wind/full_composite_npz/{year}{month}{day}{valid_time}00_conv_wind_composite_data.npz'\n",
    "    return np.load(file_path)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your datetime (including time)\n",
    "    datetime_str = '2019-06-15 15:40:00'\n",
    "    \n",
    "    # Filter rows by exact datetime\n",
    "    filtered_df = filter_rows_by_datetime(merged_df, datetime_str)\n",
    "    print(\"Filtered DataFrame:\")\n",
    "    print(filtered_df)\n",
    "    \n",
    "    # Load corresponding .npz file\n",
    "    if not filtered_df.empty:\n",
    "        data = load_npz_file(pd.to_datetime(datetime_str))\n",
    "        ZH, rad_shear, KDP = data['ZH_max'], data['RAD_SHEAR_LLSD_max'], data['KDP_max']\n",
    "        print(\"\\nLoaded Arrays:\")\n",
    "        print(\"ZH:\", ZH.shape)  # Check array dimensions instead of printing NaNs\n",
    "\n",
    "    # Anchor the fields in the Swiss grid\n",
    "    anchored_data = {\n",
    "        'ZH': ZH,\n",
    "        'rad_shear': rad_shear,\n",
    "        'KDP': KDP,\n",
    "        'easting': X,\n",
    "        'northing': Y,\n",
    "        'longitude': clons,\n",
    "        'latitude': clats\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon 65824: ZH_mean=33.42625899280576, rad_shear_mean=0.8936572488584474, KDP_mean=0.2168462150155302\n",
      "Polygon 65825: ZH_mean=30.273853211009175, rad_shear_mean=1.264913480168181, KDP_mean=0.2577336938752685\n",
      "Polygon 65826: ZH_mean=30.45323696565357, rad_shear_mean=1.4282164039450904, KDP_mean=0.36946686962852826\n",
      "Polygon 65827: ZH_mean=32.52226093689508, rad_shear_mean=1.0485383174016945, KDP_mean=0.2083675434631018\n",
      "Polygon 65828: ZH_mean=31.240995957368614, rad_shear_mean=1.0089569160997733, KDP_mean=0.2543439922548533\n",
      "Polygon 65829: ZH_mean=29.94159511974695, rad_shear_mean=0.7412602045496238, KDP_mean=0.11283771152843185\n",
      "Polygon 65830: ZH_mean=27.208668197474168, rad_shear_mean=0.5035538222582387, KDP_mean=0.06948033516390824\n",
      "Polygon 65831: ZH_mean=24.098255569567044, rad_shear_mean=0.373651704940849, KDP_mean=0.28318756170629866\n",
      "Polygon 65832: ZH_mean=nan, rad_shear_mean=nan, KDP_mean=nan\n",
      "Polygon 65833: ZH_mean=28.680182599355533, rad_shear_mean=0.6422176839293054, KDP_mean=0.14366940546364193\n",
      "Polygon 65834: ZH_mean=30.532617342879874, rad_shear_mean=0.7178683468081524, KDP_mean=0.2047072209328783\n",
      "Polygon 65835: ZH_mean=28.93590240123935, rad_shear_mean=0.7178622159090909, KDP_mean=0.11779901928319753\n",
      "Polygon 65836: ZH_mean=32.15772752387718, rad_shear_mean=0.6792289444548403, KDP_mean=0.14893381131176825\n",
      "Polygon 65837: ZH_mean=35.64676039119804, rad_shear_mean=0.3735943168077388, KDP_mean=0.15121973857947982\n",
      "Polygon 65838: ZH_mean=30.45801687763713, rad_shear_mean=0.4992559523809526, KDP_mean=0.11966397157796531\n",
      "Polygon 65839: ZH_mean=25.472658440830063, rad_shear_mean=0.7860560367928826, KDP_mean=0.2962942106890222\n",
      "Polygon 65840: ZH_mean=nan, rad_shear_mean=nan, KDP_mean=nan\n",
      "Polygon 65841: ZH_mean=30.514084123351857, rad_shear_mean=0.9163040161764098, KDP_mean=0.14069036027902257\n",
      "Polygon 65842: ZH_mean=32.44771863117871, rad_shear_mean=0.5242598684210527, KDP_mean=0.03992511016076698\n",
      "Polygon 65843: ZH_mean=33.64084249084249, rad_shear_mean=-0.13770102339181287, KDP_mean=0.023198776410115474\n",
      "Polygon 65844: ZH_mean=32.447251621713896, rad_shear_mean=0.83055966469428, KDP_mean=0.8663747712862562\n",
      "Polygon 65845: ZH_mean=34.658203125, rad_shear_mean=0.13822751322751325, KDP_mean=0.1383307134077475\n",
      "Polygon 65846: ZH_mean=39.94457350272232, rad_shear_mean=2.0823368473895583, KDP_mean=0.8038171853543006\n",
      "Polygon 65847: ZH_mean=42.10209955976973, rad_shear_mean=2.207705077018915, KDP_mean=0.7487750109238174\n",
      "Polygon 65848: ZH_mean=36.99400715563506, rad_shear_mean=2.542708333333333, KDP_mean=0.5139806290548868\n",
      "Polygon 65849: ZH_mean=36.535458879618595, rad_shear_mean=1.703260577749141, KDP_mean=0.5962379624277987\n",
      "Polygon 65850: ZH_mean=34.87517029972752, rad_shear_mean=1.9875622966577933, KDP_mean=0.3121856040854481\n",
      "Polygon 65851: ZH_mean=34.66705636229387, rad_shear_mean=1.5999923594132026, KDP_mean=0.25072586631443056\n",
      "Polygon 65852: ZH_mean=27.186287477954146, rad_shear_mean=0.9009276943220481, KDP_mean=0.5856408592710062\n",
      "Polygon 65853: ZH_mean=26.382474820933616, rad_shear_mean=0.7422470597533607, KDP_mean=0.4121186008738583\n",
      "Polygon 65854: ZH_mean=24.926251036770804, rad_shear_mean=0.47606197373238146, KDP_mean=0.3559259592341736\n",
      "Polygon 65855: ZH_mean=31.263633481293596, rad_shear_mean=-0.16067918912848161, KDP_mean=0.23830200024165005\n",
      "Polygon 65856: ZH_mean=28.703978159126365, rad_shear_mean=-0.0714608882643502, KDP_mean=0.45549835907471203\n",
      "Polygon 65857: ZH_mean=31.979766803840878, rad_shear_mean=0.1889140905017921, KDP_mean=0.4278831088343945\n",
      "Polygon 65858: ZH_mean=31.455968832696264, rad_shear_mean=0.4102992257314237, KDP_mean=0.18019667334135986\n",
      "Polygon 65859: ZH_mean=31.32074175824176, rad_shear_mean=0.20844414893617022, KDP_mean=0.141158233507136\n",
      "Polygon 65860: ZH_mean=30.426844783715012, rad_shear_mean=0.3534283980582525, KDP_mean=0.13240618441986637\n",
      "Polygon 65861: ZH_mean=28.08425490738181, rad_shear_mean=0.7533440669769975, KDP_mean=0.45991769008869277\n",
      "Polygon 65862: ZH_mean=34.63907294741281, rad_shear_mean=1.1776187031994554, KDP_mean=1.0195661591238268\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Example: Iterate over polygons in filtered_df\n",
    "for index, row in filtered_df.iterrows():\n",
    "    polygon = row['geometry']  # Assuming 'geometry' contains shapely Polygon objects\n",
    "    \n",
    "    # Create a mask for grid points inside the polygon\n",
    "    mask = np.array([\n",
    "        polygon.contains(Point(lon, lat))\n",
    "        for lon, lat in zip(clons.flatten(), clats.flatten())\n",
    "    ]).reshape(clons.shape)  # Reshape mask to match grid dimensions\n",
    "    \n",
    "    # Extract values from ZH, rad_shear, KDP within the polygon\n",
    "    ZH_in_polygon = ZH[mask]\n",
    "    rad_shear_in_polygon = rad_shear[mask]\n",
    "    KDP_in_polygon = KDP[mask]\n",
    "    \n",
    "    # Aggregate or process values as needed (e.g., mean, max)\n",
    "    ZH_mean = np.nanmean(ZH_in_polygon)\n",
    "    rad_shear_mean = np.nanmean(rad_shear_in_polygon)\n",
    "    KDP_mean = np.nanmean(KDP_in_polygon)\n",
    "    \n",
    "    print(f\"Polygon {index}: ZH_mean={ZH_mean}, rad_shear_mean={rad_shear_mean}, KDP_mean={KDP_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp                                           geometry  \\\n",
      "65824 2019-06-15 15:40:00  POLYGON ((8.4515 45.9795, 8.4514 45.9705, 8.43...   \n",
      "65825 2019-06-15 15:40:00  POLYGON ((7.3669 46.6047, 7.3669 46.5777, 7.35...   \n",
      "65826 2019-06-15 15:40:00  POLYGON ((7.6538 46.5596, 7.6277 46.5416, 7.60...   \n",
      "65827 2019-06-15 15:40:00  POLYGON ((8.356 46.4391, 8.3559 46.4301, 8.342...   \n",
      "65828 2019-06-15 15:40:00  POLYGON ((8.1463 46.3237, 8.1201 46.3059, 8.11...   \n",
      "\n",
      "      CS Marker STA Marker ESWD Marker Gust_Flag             traj_ID  \\\n",
      "65824         0          0           0         -  2019061515350113.0   \n",
      "65825         0          0           0         -  2019061514550083.0   \n",
      "65826         0          0           0         -  2019061515300099.0   \n",
      "65827         0          0           0         -  2019061515350107.0   \n",
      "65828         0          0           0         -  2019061515200086.0   \n",
      "\n",
      "               time     lon      lat  ... nrPOHthr070 nrPOHthr080 nrPOHthr090  \\\n",
      "65824  2.019062e+11   8.466  45.9344  ...         NaN         NaN         NaN   \n",
      "65825  2.019062e+11  7.3255  46.4688  ...         NaN         NaN         NaN   \n",
      "65826  2.019062e+11   7.625  46.4964  ...         NaN         NaN         NaN   \n",
      "65827  2.019062e+11  8.2978  46.3686  ...         NaN         NaN         NaN   \n",
      "65828  2.019062e+11  8.1596  46.2682  ...         NaN         NaN         NaN   \n",
      "\n",
      "      nrPOHthr100 ZH_com_height ZH_percent_above_45 KDP_com_height  \\\n",
      "65824         NaN           NaN            2.795699            NaN   \n",
      "65825         NaN           NaN            5.569689            NaN   \n",
      "65826         NaN           NaN            2.489205            NaN   \n",
      "65827         NaN           NaN            5.361410            NaN   \n",
      "65828         NaN           NaN            0.658602            NaN   \n",
      "\n",
      "      KDP_percent_above_2 rad_shear_max rad_shear_percent_above_2  \n",
      "65824            0.000000      6.760417                  3.672457  \n",
      "65825            0.298497      5.729167                 10.586479  \n",
      "65826            0.685801      7.022321                  7.018881  \n",
      "65827            0.000000      5.270833                  5.137395  \n",
      "65828            0.000000      3.838542                  4.905914  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_127583/1982778634.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['ZH_com_height'] = ZH_com_height\n",
      "/tmp/ipykernel_127583/1982778634.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['ZH_percent_above_45'] = ZH_percent_above_45\n",
      "/tmp/ipykernel_127583/1982778634.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['KDP_com_height'] = KDP_com_height\n",
      "/tmp/ipykernel_127583/1982778634.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['KDP_percent_above_2'] = KDP_percent_above_2\n",
      "/tmp/ipykernel_127583/1982778634.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['rad_shear_max'] = rad_shear_max\n",
      "/tmp/ipykernel_127583/1982778634.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['rad_shear_percent_above_2'] = rad_shear_percent_above_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "def calculate_metrics(filtered_df, clons, clats, ZH, rad_shear, KDP):\n",
    "    # Initialize lists to store results\n",
    "    ZH_com_height = []\n",
    "    ZH_percent_above_45 = []\n",
    "    KDP_com_height = []\n",
    "    KDP_percent_above_2 = []\n",
    "    rad_shear_max = []\n",
    "    rad_shear_percent_above_2 = []\n",
    "\n",
    "    # Iterate over rows in filtered_df\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        polygon = row['geometry']  # Shapely Polygon object\n",
    "        \n",
    "        # Create a mask for grid points inside the polygon (2D mask)\n",
    "        mask_2d = np.array([\n",
    "            polygon.contains(Point(lon, lat))\n",
    "            for lon, lat in zip(clons.flatten(), clats.flatten())\n",
    "        ]).reshape(clons.shape)  # Reshape mask to match grid dimensions\n",
    "        \n",
    "        # Extend the mask to 3D by repeating along the vertical dimension\n",
    "        mask_3d = np.repeat(mask_2d[:, :, np.newaxis], ZH.shape[2], axis=2)\n",
    "        \n",
    "        # Extract values within the polygon for ZH, KDP, rad_shear\n",
    "        ZH_in_polygon = ZH[mask_3d]\n",
    "        KDP_in_polygon = KDP[mask_3d]\n",
    "        rad_shear_in_polygon = rad_shear[mask_3d]\n",
    "        \n",
    "        # Calculate metrics for ZH\n",
    "        if np.any(ZH_in_polygon > 0):  # Avoid division by zero\n",
    "            com_ZH = center_of_mass(ZH * mask_3d)  # Center of mass height\n",
    "            ZH_com_height.append(com_ZH[2])  # Use the vertical dimension (z-axis)\n",
    "            ZH_percent_above_45.append(np.sum(ZH_in_polygon > 45) / np.size(ZH_in_polygon) * 100)\n",
    "        else:\n",
    "            ZH_com_height.append(np.nan)\n",
    "            ZH_percent_above_45.append(0)\n",
    "        \n",
    "        # Calculate metrics for KDP\n",
    "        if np.any(KDP_in_polygon > 0):  # Avoid division by zero\n",
    "            com_KDP = center_of_mass(KDP * mask_3d)  # Center of mass height\n",
    "            KDP_com_height.append(com_KDP[2])  # Use the vertical dimension (z-axis)\n",
    "            KDP_percent_above_2.append(np.sum(KDP_in_polygon > 2) / np.size(KDP_in_polygon) * 100)\n",
    "        else:\n",
    "            KDP_com_height.append(np.nan)\n",
    "            KDP_percent_above_2.append(0)\n",
    "        \n",
    "        # Calculate metrics for rad_shear\n",
    "        if np.any(rad_shear_in_polygon > 0):  # Avoid division by zero\n",
    "            rad_shear_max.append(np.nanmax(rad_shear_in_polygon))\n",
    "            rad_shear_percent_above_2.append(np.sum(rad_shear_in_polygon > 2) / np.size(rad_shear_in_polygon) * 100)\n",
    "        else:\n",
    "            rad_shear_max.append(np.nan)\n",
    "            rad_shear_percent_above_2.append(0)\n",
    "\n",
    "    # Add results as new columns in filtered_df\n",
    "    filtered_df['ZH_com_height'] = ZH_com_height\n",
    "    filtered_df['ZH_percent_above_45'] = ZH_percent_above_45\n",
    "    filtered_df['KDP_com_height'] = KDP_com_height\n",
    "    filtered_df['KDP_percent_above_2'] = KDP_percent_above_2\n",
    "    filtered_df['rad_shear_max'] = rad_shear_max\n",
    "    filtered_df['rad_shear_percent_above_2'] = rad_shear_percent_above_2\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming clons, clats, ZH, rad_shear, KDP are already defined and filtered_df contains 'geometry' column.\n",
    "filtered_df = calculate_metrics(filtered_df, clons, clats, ZH, rad_shear, KDP)\n",
    "\n",
    "# Display updated DataFrame with new columns\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "def calculate_metrics(filtered_df, clons, clats, ZH, rad_shear, KDP):\n",
    "    # Initialize lists to store results\n",
    "    ZH_com_height = []\n",
    "    ZH_percent_above_45 = []\n",
    "    KDP_com_height = []\n",
    "    KDP_percent_above_2 = []\n",
    "    rad_shear_max = []\n",
    "    rad_shear_percent_above_2 = []\n",
    "\n",
    "    # Iterate over rows in filtered_df\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        polygon = row['geometry']  # Shapely Polygon object\n",
    "        \n",
    "        # Create a mask for grid points inside the polygon (2D mask)\n",
    "        mask_2d = np.array([\n",
    "            polygon.contains(Point(lon, lat))\n",
    "            for lon, lat in zip(clons.flatten(), clats.flatten())\n",
    "        ]).reshape(clons.shape)  # Reshape mask to match grid dimensions\n",
    "        \n",
    "        # Extend the mask to 3D by repeating along the vertical dimension\n",
    "        mask_3d = np.repeat(mask_2d[:, :, np.newaxis], ZH.shape[2], axis=2)\n",
    "        \n",
    "        # Apply the mask directly to retain 3D structure\n",
    "        ZH_masked = np.where(mask_3d, ZH, np.nan)  # Replace values outside the polygon with NaN\n",
    "        KDP_masked = np.where(mask_3d, KDP, np.nan)  # Replace values outside the polygon with NaN\n",
    "        rad_shear_masked = np.where(mask_3d, rad_shear, np.nan)  # Replace values outside the polygon with NaN\n",
    "        \n",
    "        # Replace NaN values with 0 for calculations\n",
    "        ZH_masked[np.isnan(ZH_masked)] = 0\n",
    "        KDP_masked[np.isnan(KDP_masked)] = 0\n",
    "        rad_shear_masked[np.isnan(rad_shear_masked)] = 0\n",
    "        \n",
    "        # Calculate metrics for ZH\n",
    "        if np.any(ZH_masked > 0):  # Check if there are valid values\n",
    "            com_ZH = center_of_mass(ZH_masked)  # Center of mass height\n",
    "            ZH_com_height.append(com_ZH[2])  # Use the vertical dimension (z-axis)\n",
    "            ZH_percent_above_45.append(np.sum(ZH_masked > 45) / np.size(ZH_masked) * 100)\n",
    "        else:\n",
    "            ZH_com_height.append(np.nan)\n",
    "            ZH_percent_above_45.append(0)\n",
    "        \n",
    "        # Calculate metrics for KDP\n",
    "        if np.any(KDP_masked > 0):  # Check if there are valid values\n",
    "            com_KDP = center_of_mass(KDP_masked)  # Center of mass height\n",
    "            KDP_com_height.append(com_KDP[2])  # Use the vertical dimension (z-axis)\n",
    "            KDP_percent_above_2.append(np.sum(KDP_masked > 2) / np.size(KDP_masked) * 100)\n",
    "        else:\n",
    "            KDP_com_height.append(np.nan)\n",
    "            KDP_percent_above_2.append(0)\n",
    "        \n",
    "        # Calculate metrics for rad_shear\n",
    "        if np.any(rad_shear_masked > 0):  # Check if there are valid values\n",
    "            rad_shear_max.append(np.nanmax(rad_shear_masked))\n",
    "            rad_shear_percent_above_2.append(np.sum(rad_shear_masked > 2) / np.size(rad_shear_masked) * 100)\n",
    "        else:\n",
    "            rad_shear_max.append(np.nan)\n",
    "            rad_shear_percent_above_2.append(0)\n",
    "\n",
    "    # Add results as new columns in filtered_df\n",
    "    filtered_df['ZH_com_height'] = ZH_com_height\n",
    "    filtered_df['ZH_percent_above_45'] = ZH_percent_above_45\n",
    "    filtered_df['KDP_com_height'] = KDP_com_height\n",
    "    filtered_df['KDP_percent_above_2'] = KDP_percent_above_2\n",
    "    filtered_df['rad_shear_max'] = rad_shear_max\n",
    "    filtered_df['rad_shear_percent_above_2'] = rad_shear_percent_above_2\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming clons, clats, ZH, rad_shear, KDP are already defined and filtered_df contains 'geometry' column.\n",
    "filtered_df = calculate_metrics(filtered_df, clons, clats, ZH, rad_shear, KDP)\n",
    "\n",
    "# Display updated DataFrame with new columns\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Mask Shape: (640, 710)\n",
      "Number of points inside polygon: 65\n",
      "3D Mask Shape: (640, 710, 93)\n",
      "ZH_masked shape: (640, 710, 93)\n",
      "KDP_masked shape: (640, 710, 93)\n",
      "ZH_com_height (manual): 18.861113032783734\n",
      "KDP_com_height (manual): 10.932824382256758\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def process_one_row(row, clons, clats, ZH, KDP):\n",
    "    polygon = row['geometry']  # Shapely Polygon object\n",
    "    \n",
    "    # Step 1: Create a 2D mask for points inside the polygon\n",
    "    mask_2d = np.array([\n",
    "        polygon.contains(Point(lon, lat))\n",
    "        for lon, lat in zip(clons.flatten(), clats.flatten())\n",
    "    ]).reshape(clons.shape)  # Reshape mask to match grid dimensions\n",
    "    \n",
    "    print(\"2D Mask Shape:\", mask_2d.shape)\n",
    "    print(\"Number of points inside polygon:\", np.sum(mask_2d))\n",
    "    \n",
    "    # Step 2: Extend the 2D mask to 3D\n",
    "    mask_3d = np.repeat(mask_2d[:, :, np.newaxis], ZH.shape[2], axis=2)\n",
    "    print(\"3D Mask Shape:\", mask_3d.shape)\n",
    "    \n",
    "    # Step 3: Apply the mask directly to retain 3D structure\n",
    "    ZH_masked = np.where(mask_3d, ZH, np.nan)  # Retain original shape with NaN outside the polygon\n",
    "    KDP_masked = np.where(mask_3d, KDP, np.nan)  # Retain original shape with NaN outside the polygon\n",
    "    \n",
    "    print(\"ZH_masked shape:\", ZH_masked.shape)\n",
    "    print(\"KDP_masked shape:\", KDP_masked.shape)\n",
    "    \n",
    "    # Step 4: Calculate center of mass for ZH (only within valid values)\n",
    "    if np.any(~np.isnan(ZH_masked)):  # Check if there are any valid values\n",
    "        total_mass_ZH = np.nansum(ZH_masked)\n",
    "        if total_mass_ZH > 0:\n",
    "            z_indices = np.arange(ZH.shape[2])  # Vertical indices (z-axis)\n",
    "            com_ZH_height = np.nansum(np.nansum(ZH_masked, axis=(0, 1)) * z_indices) / total_mass_ZH\n",
    "        else:\n",
    "            com_ZH_height = None\n",
    "    else:\n",
    "        com_ZH_height = None\n",
    "    \n",
    "    print(\"ZH_com_height (manual):\", com_ZH_height)\n",
    "    \n",
    "    # Step 5: Calculate center of mass for KDP (only within valid values)\n",
    "    if np.any(~np.isnan(KDP_masked)):  # Check if there are any valid values\n",
    "        total_mass_KDP = np.nansum(KDP_masked)\n",
    "        if total_mass_KDP > 0:\n",
    "            z_indices = np.arange(KDP.shape[2])  # Vertical indices (z-axis)\n",
    "            com_KDP_height = np.nansum(np.nansum(KDP_masked, axis=(0, 1)) * z_indices) / total_mass_KDP\n",
    "        else:\n",
    "            com_KDP_height = None\n",
    "    else:\n",
    "        com_KDP_height = None\n",
    "    \n",
    "    print(\"KDP_com_height (manual):\", com_KDP_height)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming filtered_df contains 'geometry', clons, clats, ZH, and KDP are already defined.\n",
    "row = filtered_df.iloc[0]  # Select one row for debugging\n",
    "process_one_row(row, clons, clats, ZH, KDP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Mask Shape: (640, 710)\n",
      "Number of points inside polygon: 65\n",
      "3D Mask Shape: (640, 710, 93)\n",
      "ZH_masked shape: (640, 710, 93)\n",
      "KDP_masked shape: (640, 710, 93)\n",
      "ZH_masked - NaN count: 42257254, Non-NaN count: 1946\n",
      "KDP_masked - NaN count: 42257052, Non-NaN count: 2148\n",
      "After replacing NaNs:\n",
      "ZH_masked - NaN count after: 0, Non-NaN count after: 42259200\n",
      "KDP_masked - NaN count after: 0, Non-NaN count after: 42259200\n",
      "ZH_com_height (center_of_mass): 18.861113032783734\n",
      "KDP_com_height (center_of_mass): 10.93282438225676\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "def process_one_row(row, clons, clats, ZH, KDP):\n",
    "    polygon = row['geometry']  # Shapely Polygon object\n",
    "    \n",
    "    # Step 1: Create a 2D mask for points inside the polygon\n",
    "    mask_2d = np.array([\n",
    "        polygon.contains(Point(lon, lat))\n",
    "        for lon, lat in zip(clons.flatten(), clats.flatten())\n",
    "    ]).reshape(clons.shape)  # Reshape mask to match grid dimensions\n",
    "    \n",
    "    print(\"2D Mask Shape:\", mask_2d.shape)\n",
    "    print(\"Number of points inside polygon:\", np.sum(mask_2d))\n",
    "    \n",
    "    # Step 2: Extend the 2D mask to 3D\n",
    "    mask_3d = np.repeat(mask_2d[:, :, np.newaxis], ZH.shape[2], axis=2)\n",
    "    print(\"3D Mask Shape:\", mask_3d.shape)\n",
    "    \n",
    "    # Step 3: Apply the mask directly to retain 3D structure\n",
    "    ZH_masked = np.where(mask_3d, ZH, np.nan)  # Replace values outside the polygon with NaN\n",
    "    KDP_masked = np.where(mask_3d, KDP, np.nan)  # Replace values outside the polygon with NaN\n",
    "    \n",
    "    print(\"ZH_masked shape:\", ZH_masked.shape)\n",
    "    print(\"KDP_masked shape:\", KDP_masked.shape)\n",
    "    \n",
    "    # Debugging: Count NaN and non-NaN values in ZH_masked and KDP_masked\n",
    "    nan_count_ZH = np.count_nonzero(np.isnan(ZH_masked))\n",
    "    non_nan_count_ZH = np.count_nonzero(~np.isnan(ZH_masked))\n",
    "    \n",
    "    nan_count_KDP = np.count_nonzero(np.isnan(KDP_masked))\n",
    "    non_nan_count_KDP = np.count_nonzero(~np.isnan(KDP_masked))\n",
    "    \n",
    "    print(f\"ZH_masked - NaN count: {nan_count_ZH}, Non-NaN count: {non_nan_count_ZH}\")\n",
    "    print(f\"KDP_masked - NaN count: {nan_count_KDP}, Non-NaN count: {non_nan_count_KDP}\")\n",
    "    \n",
    "    # Step 4: Replace NaN values with 0\n",
    "    ZH_masked[np.isnan(ZH_masked)] = 0\n",
    "    KDP_masked[np.isnan(KDP_masked)] = 0\n",
    "    \n",
    "    print(\"After replacing NaNs:\")\n",
    "    nan_count_ZH_after = np.count_nonzero(np.isnan(ZH_masked))\n",
    "    non_nan_count_ZH_after = np.count_nonzero(~np.isnan(ZH_masked))\n",
    "    \n",
    "    nan_count_KDP_after = np.count_nonzero(np.isnan(KDP_masked))\n",
    "    non_nan_count_KDP_after = np.count_nonzero(~np.isnan(KDP_masked))\n",
    "    \n",
    "    print(f\"ZH_masked - NaN count after: {nan_count_ZH_after}, Non-NaN count after: {non_nan_count_ZH_after}\")\n",
    "    print(f\"KDP_masked - NaN count after: {nan_count_KDP_after}, Non-NaN count after: {non_nan_count_KDP_after}\")\n",
    "    \n",
    "    # Step 5: Calculate center of mass using scipy.ndimage.center_of_mass\n",
    "    try:\n",
    "        com_ZH = center_of_mass(ZH_masked)\n",
    "        ZH_com_height = com_ZH[2] if not np.isnan(com_ZH[2]) else None\n",
    "    except Exception as e:\n",
    "        print(\"Error calculating ZH center of mass:\", e)\n",
    "        ZH_com_height = None\n",
    "    \n",
    "    print(\"ZH_com_height (center_of_mass):\", ZH_com_height)\n",
    "    \n",
    "    try:\n",
    "        com_KDP = center_of_mass(KDP_masked)\n",
    "        KDP_com_height = com_KDP[2] if not np.isnan(com_KDP[2]) else None\n",
    "    except Exception as e:\n",
    "        print(\"Error calculating KDP center of mass:\", e)\n",
    "        KDP_com_height = None\n",
    "    \n",
    "    print(\"KDP_com_height (center_of_mass):\", KDP_com_height)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming filtered_df contains 'geometry', clons, clats, ZH, and KDP are already defined.\n",
    "row = filtered_df.iloc[0]  # Select one row for debugging\n",
    "process_one_row(row, clons, clats, ZH, KDP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
