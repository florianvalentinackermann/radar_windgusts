{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pyart\n",
    "import glob\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "from pyproj import Transformer\n",
    "import radlib\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import xmltodict, geopandas, geojson, xml #xml and json do not exist\n",
    "from datetime import datetime, timedelta\n",
    "import geopy.distance\n",
    "from datetime import datetime, timedelta\n",
    "import numpy.matlib as npm\n",
    "import copy\n",
    "from scipy.signal import convolve2d\n",
    "from astropy.convolution import convolve\n",
    "import scipy.ndimage as ndi\n",
    "import re\n",
    "from skimage.draw import polygon\n",
    "\n",
    "os.environ[\"library_metranet_path\"] = \"/store_new/mch/msrad/idl/lib/radlib4/\" # needed for pyradlib\n",
    "os.environ[\"METRANETLIB_PATH\"] = \"/store_new/mch/msrad/idl/lib/radlib4/\" # needed for pyart_mch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining valid time and elevation scan\n",
    "\n",
    "valid_time3 = '1900'\n",
    "elevation_scan = '3'\n",
    "radar_station = 'A'\n",
    "radar_name = 'Albis'\n",
    "day = '3' # 3 or 4\n",
    "calendar_day = '12' # 12 or 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGS84: \n",
      "[46.54620053012867, 7.017760746224894, 2024.97379732]\n",
      "LV03: \n",
      "[567719, 155077, 1974]\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n",
      "swap product table data ......\n",
      "py_decoder DBG verb=0\n",
      "py_decoder DBG verbl=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_210264/820652375.py:236: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  headers=pd.read_csv(file).iloc[7:8].iloc[0][0].split()\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n",
      "/tmp/ipykernel_210264/820652375.py:240: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
      "/tmp/ipykernel_210264/820652375.py:241: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trt_df.loc[n,'time']=int(t[1].values)\n",
      "/tmp/ipykernel_210264/820652375.py:261: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cells[rr,cc]=int(t[0].values);\n"
     ]
    }
   ],
   "source": [
    "# Data Imports, processing, norming, etc.\n",
    "\n",
    "# Classify the GPSConverter for Cooridnate system transformation\n",
    "class GPSConverter(object):\n",
    "    '''\n",
    "    GPS Converter class which is able to perform convertions between the \n",
    "    CH1903 and WGS84 system.\n",
    "    '''\n",
    "    # Convert CH y/x/h to WGS height\n",
    "    def CHtoWGSheight(self, y, x, h):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        h = (h + 49.55) - (12.60 * y_aux) - (22.64 * x_aux)\n",
    "        return h\n",
    "\n",
    "    # Convert CH y/x to WGS lat\n",
    "    def CHtoWGSlat(self, y, x):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        lat = (16.9023892 + (3.238272 * x_aux)) + \\\n",
    "                - (0.270978 * pow(y_aux, 2)) + \\\n",
    "                - (0.002528 * pow(x_aux, 2)) + \\\n",
    "                - (0.0447 * pow(y_aux, 2) * x_aux) + \\\n",
    "                - (0.0140 * pow(x_aux, 3))\n",
    "        # Unit 10000\" to 1\" and convert seconds to degrees (dec)\n",
    "        lat = (lat * 100) / 36\n",
    "        return lat\n",
    "\n",
    "    # Convert CH y/x to WGS long\n",
    "    def CHtoWGSlng(self, y, x):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        lng = (2.6779094 + (4.728982 * y_aux) + \\\n",
    "                + (0.791484 * y_aux * x_aux) + \\\n",
    "                + (0.1306 * y_aux * pow(x_aux, 2))) + \\\n",
    "                - (0.0436 * pow(y_aux, 3))\n",
    "        # Unit 10000\" to 1\" and convert seconds to degrees (dec)\n",
    "        lng = (lng * 100) / 36\n",
    "        return lng\n",
    "\n",
    "    # Convert decimal angle (째 dec) to sexagesimal angle (dd.mmss,ss)\n",
    "    def DecToSexAngle(self, dec):\n",
    "        degree = int(math.floor(dec))\n",
    "        minute = int(math.floor((dec - degree) * 60))\n",
    "        second = (((dec - degree) * 60) - minute) * 60\n",
    "        return degree + (float(minute) / 100) + (second / 10000)\n",
    "\t\t\n",
    "    # Convert sexagesimal angle (dd.mmss,ss) to seconds\n",
    "    def SexAngleToSeconds(self, dms):\n",
    "        degree = 0 \n",
    "        minute = 0 \n",
    "        second = 0\n",
    "        degree = math.floor(dms)\n",
    "        minute = math.floor((dms - degree) * 100)\n",
    "        second = (((dms - degree) * 100) - minute) * 100\n",
    "        return second + (minute * 60) + (degree * 3600)\n",
    "\n",
    "    # Convert sexagesimal angle (dd.mmss) to decimal angle (degrees)\n",
    "    def SexToDecAngle(self, dms):\n",
    "        degree = 0\n",
    "        minute = 0\n",
    "        second = 0\n",
    "        degree = math.floor(dms)\n",
    "        minute = math.floor((dms - degree) * 100)\n",
    "        second = (((dms - degree) * 100) - minute) * 100\n",
    "        return degree + (minute / 60) + (second / 3600)\n",
    "    \n",
    "    # Convert WGS lat/long (째 dec) and height to CH h\n",
    "    def WGStoCHh(self, lat, lng, h):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        h = (h - 49.55) + (2.73 * lng_aux) + (6.94 * lat_aux)\n",
    "        return h\n",
    "\n",
    "    # Convert WGS lat/long (째 dec) to CH x\n",
    "    def WGStoCHx(self, lat, lng):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        x = ((200147.07 + (308807.95 * lat_aux) + \\\n",
    "            + (3745.25 * pow(lng_aux, 2)) + \\\n",
    "            + (76.63 * pow(lat_aux,2))) + \\\n",
    "            - (194.56 * pow(lng_aux, 2) * lat_aux)) + \\\n",
    "            + (119.79 * pow(lat_aux, 3))\n",
    "        return x\n",
    "\n",
    "\t# Convert WGS lat/long (째 dec) to CH y\n",
    "    def WGStoCHy(self, lat, lng):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        y = (600072.37 + (211455.93 * lng_aux)) + \\\n",
    "            - (10938.51 * lng_aux * lat_aux) + \\\n",
    "            - (0.36 * lng_aux * pow(lat_aux, 2)) + \\\n",
    "            - (44.54 * pow(lng_aux, 3))\n",
    "        return y\n",
    "\n",
    "    def LV03toWGS84(self, east, north, height):\n",
    "        '''\n",
    "        Convert LV03 to WGS84 Return a array of double that contain lat, long,\n",
    "        and height\n",
    "        '''\n",
    "        d = []\n",
    "        d.append(self.CHtoWGSlat(east, north))\n",
    "        d.append(self.CHtoWGSlng(east, north))\n",
    "        d.append(self.CHtoWGSheight(east, north, height))\n",
    "        return d\n",
    "        \n",
    "    def WGS84toLV03(self, latitude, longitude, ellHeight):\n",
    "        '''\n",
    "        Convert WGS84 to LV03 Return an array of double that contaign east,\n",
    "        north, and height\n",
    "        '''\n",
    "        d = []\n",
    "        d.append(self.WGStoCHy(latitude, longitude))\n",
    "        d.append(self.WGStoCHx(latitude, longitude))\n",
    "        d.append(self.WGStoCHh(latitude, longitude, ellHeight))\n",
    "        return d\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    ''' Example usage for the GPSConverter class.'''\n",
    "\n",
    "    converter = GPSConverter()\n",
    "\n",
    "    # Coordinates\n",
    "    wgs84 = []\n",
    "    lv03  = [567719, 155077, 1974]\n",
    "    #567719/ 155077  Altitude: 1974\n",
    "    # Convert WGS84 to LV03 coordinates\n",
    "    wgs84 = converter.LV03toWGS84(lv03[0], lv03[1], lv03[2])\n",
    "\n",
    "    print(\"WGS84: \")\n",
    "    print(wgs84)\n",
    "    print(\"LV03: \")\n",
    "    print(lv03)\n",
    "\n",
    "# Transform function for dealiased velocity\n",
    "def transform_from_digital(mydata, nyquist):\n",
    "    myfinaldata = (mydata * 1.0 - 128) * nyquist / 127\n",
    "    myfinaldata[mydata == 0] = np.nan\n",
    "    return myfinaldata\n",
    "\n",
    "# Convert polar coordinates (range, azimuth) to geographic coordinates (lat/lon)\n",
    "def radar_to_latlon(radar_lat, radar_lon, ranges, azimuths):\n",
    "    R = 6371.0  # Earth radius in kilometers\n",
    "    azimuths_rad = np.radians(azimuths)\n",
    "    latitudes = np.zeros((len(azimuths), len(ranges)))\n",
    "    longitudes = np.zeros((len(azimuths), len(ranges)))\n",
    "\n",
    "    for i, az in enumerate(azimuths_rad):\n",
    "        latitudes[i, :] = radar_lat + (ranges / R) * np.cos(az) * (180.0 / np.pi)\n",
    "        longitudes[i, :] = radar_lon + (ranges / R) * np.sin(az) * (180.0 / np.pi) / np.cos(np.radians(radar_lat))\n",
    "\n",
    "    return latitudes, longitudes\n",
    "\n",
    "# Define TRT reading function\n",
    "def read_TRT(path, file=0, ttime=0):\n",
    "    \"\"\"\n",
    "    Read .trt or .json file containing TRT output\n",
    "    Returns dataframe with attributes and gridded TRT cells\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    path : string\n",
    "        path, where to look for files.\n",
    "    file: string\n",
    "        filename\n",
    "    ttime : string\n",
    "        timestep to find files for.\n",
    "    Requires either filename or timestep\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    trt_df : dataframe\n",
    "        TRT cells and attributes of the timestep.\n",
    "    cells: list\n",
    "        Gridded TRT cells per timestep\n",
    "    timelist: list\n",
    "        timesteps\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    o_x=254000\n",
    "    o_y=-159000\n",
    "    lx=710; ly=640\n",
    "    cells=np.zeros([ly,lx])\n",
    "    if file == 0:\n",
    "        file=glob.glob(path[\"lomdata\"]+'TRTC/*'+ttime+'*json*')\n",
    "        if len(file)>0: flag=1\n",
    "        else:\n",
    "            file=glob.glob(path[\"lomdata\"]+'TRTC/*'+ttime+'*'+'.trt')[0]\n",
    "            flag=0\n",
    "    else:\n",
    "        if 'json' in file: flag=1; ttime=file[-20:-11]\n",
    "        else: flag=0; ttime=file[-15:-6]\n",
    "        file=[file]\n",
    "   \n",
    "    if flag==1:\n",
    "        with open(file[0]) as f: gj = geojson.FeatureCollection(geojson.load(f))\n",
    "        trt_df=geopandas.GeoDataFrame.from_features(gj['features'])\n",
    "        if len(trt_df)>0:\n",
    "          # print(trt_df.lon.values.astype(float))\n",
    "          chx, chy = c_transform(trt_df.lon.values.astype(float),trt_df.lat.values.astype(float))\n",
    "          trt_df['chx']=chx.astype(str); trt_df['chy']=chy.astype(str)\n",
    "          for n in range(len(trt_df)):\n",
    "              lon,lat=trt_df.iloc[n].geometry.boundary.xy\n",
    "              # print(trt_df.iloc[n])\n",
    "              chx, chy = c_transform(lon,lat)\n",
    "              # trt_df.iloc[n]['chx']=chx.astype(str); trt_df.iloc[n]['chy']=chy.astype(str)\n",
    "              #transform.c_transform(trt_df.iloc[n].lon.values,trt_df.iloc[n].lat.values)\n",
    "              ix=np.round((chx-o_x)/1000).astype(int)\n",
    "              iy=np.round((chy-o_y)/1000).astype(int)\n",
    "              rr, cc = polygon(iy, ix, cells.shape)\n",
    "              # print(lat,lon,chx,chy,ix,iy)\n",
    "              cells[rr,cc]=int(trt_df.traj_ID.iloc[n]);\n",
    "        else: cells=[]\n",
    "    else:\n",
    "        data=pd.read_csv(file).iloc[8:]\n",
    "        headers=pd.read_csv(file).iloc[7:8].iloc[0][0].split()\n",
    "        trt_df=pd.DataFrame()\n",
    "        for n in range(len(data)):\n",
    "            t=data.iloc[n].str.split(';',expand=True)\n",
    "            trt_df.loc[n,'traj_ID']=int(t[0].values)\n",
    "            trt_df.loc[n,'time']=int(t[1].values)\n",
    "            trt_df.loc[n,'lon']=t[2].values.astype(float)\n",
    "            trt_df.loc[n,'lat']=t[3].values.astype(float)\n",
    "            chx,chy=c_transform([trt_df.loc[n,'lon']],[trt_df.loc[n,'lat']])\n",
    "            ix=np.round((chx-o_x)/1000).astype(int)\n",
    "            if ix>=710: ix=709\n",
    "            iy=np.round((chy-o_y)/1000).astype(int)\n",
    "            if iy>=640: iy=639\n",
    "            n2=27\n",
    "            if int(ttime)>=221520631: n2=82\n",
    "            tt=np.array(t)[0,n2:-1]\n",
    "            tt=np.reshape(tt,[int(len(tt)/2),2])\n",
    "            trt_df.loc[n,'chx']=chx\n",
    "            trt_df.loc[n,'chy']=chy\n",
    "            lat=tt[:,1].astype(float); lon=tt[:,0].astype(float)\n",
    "            # trt_df=trt_df.astype(str)\n",
    "            chx,chy=c_transform(lon,lat)\n",
    "            ix=np.round((chx-o_x)/1000).astype(int)\n",
    "            iy=np.round((chy-o_y)/1000).astype(int)\n",
    "            rr, cc = polygon(iy, ix, cells.shape)\n",
    "            cells[rr,cc]=int(t[0].values);\n",
    "    # print(np.nanmax(cells))\n",
    "    timelist=[str(ttime)]\n",
    "    return trt_df, [cells], timelist\n",
    "\n",
    "# Define VAD reading function\n",
    "def read_VAD(file_VAD):\n",
    "    mydoc = xml.dom.minidom.parse(file_VAD)\n",
    "\n",
    "    levels = mydoc.getElementsByTagName('level')\n",
    "   \n",
    "    heights = mydoc.getElementsByTagName('height')\n",
    "    speeds = mydoc.getElementsByTagName('speed')\n",
    "    directions = mydoc.getElementsByTagName('direction')\n",
    "   \n",
    "    vad_levels=np.zeros(len(levels))\n",
    "    vad_heights=np.zeros(len(levels))\n",
    "    vad_speeds=np.zeros(len(levels))\n",
    "    vad_directions=np.zeros(len(levels))\n",
    "    for m in range(0,len(levels)):\n",
    "        vad_levels[m]=levels[m].firstChild.data\n",
    "        vad_heights[m]=heights[m].firstChild.data\n",
    "        vad_speeds[m]=speeds[m].firstChild.data\n",
    "        vad_directions[m]=directions[m].firstChild.data\n",
    "    vad_s=np.zeros(150); vad_d=np.zeros(150); vad_s[:]=np.nan; vad_d[:]=np.nan;\n",
    "    for n in range(0,150):\n",
    "        for m in range(0,len(levels)):\n",
    "            if vad_levels[m]==n:\n",
    "                vad_s[n]=vad_speeds[m]\n",
    "                vad_d[n]=vad_directions[m]\n",
    "       \n",
    "       \n",
    "    vad_u = np.multiply(vad_s, np.cos(np.radians(vad_d)))\n",
    "    vad_v = np.multiply(vad_s, np.sin(np.radians(vad_d)))\n",
    "   \n",
    "    vadu=np.zeros(15); vadv=np.zeros(15);\n",
    "    for n in range(0,15):\n",
    "        a=n*10\n",
    "        vadu[n]=np.nanmean(vad_u[a:a+10])\n",
    "        vadv[n]=np.nanmean(vad_v[a:a+10])\n",
    "       \n",
    "    return vadu, vad_u, vadv, vad_v\n",
    "\n",
    "# Function to calculate azimuth angle from radar to downburst location\n",
    "def calculate_azimuth(lat1, lon1, lat2, lon2):\n",
    "    # Convert to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "    \n",
    "    # Calculate azimuth\n",
    "    delta_lon = lon2 - lon1\n",
    "    x = math.sin(delta_lon) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(delta_lon)\n",
    "    azimuth = math.atan2(x, y)\n",
    "    azimuth_deg = math.degrees(azimuth)\n",
    "    \n",
    "    # Normalize to 0-360 degrees\n",
    "    return (azimuth_deg + 360) % 360\n",
    "\n",
    "# Convolves and normalizes 2D data with a 3x3 kernel\n",
    "def conv(data):\n",
    "    \"\"\"\n",
    "    Convolves and normalizes 2D data with a 3x3 kernel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 2-D array\n",
    "        data to be convolved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d_conv : 2-D array\n",
    "        convolved data.\n",
    "\n",
    "    \"\"\"\n",
    "    ## convolves 2D data with a 3x3 kernel, equal weights, wrapped boundary, NaN values ignored / filled in\n",
    "    g_kernel=np.ones([3,3])/9\n",
    "    d_conv=convolve(data,g_kernel, boundary='wrap')\n",
    "    return d_conv\n",
    "\n",
    "# azimuthal centered difference derivative for polar data -> wraps around 0/360\n",
    "def az_cd(myfinaldata, nyquist, threshold, resolution, min_size):\n",
    "    \"\"\"\n",
    "    azimuthal centered difference derivative for polar data -> wraps around 0/360\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    myfinaldata : 2D array\n",
    "        input data.\n",
    "    nyquist : float\n",
    "        Nyquist velocity of raw velocity data.\n",
    "    threshold : float\n",
    "        shear correction threshold.\n",
    "    resolution : float\n",
    "        radial resolution of data.\n",
    "    min_size : int\n",
    "        minimum number of gates required for correction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    myshear_cor : 2D array\n",
    "        azimuthal derivative, corrected for unfolding errors.\n",
    "    mygateshear_cor : 2D array\n",
    "        azimuthal difference (no normalization by distance), corrected for unfolding errors.\n",
    "\n",
    "    \"\"\"\n",
    "    ## azimuthal derivative, centered difference\n",
    "    ## corrects for anomalous shear exceeding threshold\n",
    "    ## shear only corrected if contiguous area of several pixels\n",
    "    myfinaldata_1=np.zeros(myfinaldata.shape)\n",
    "    myfinaldata_1[:-1,:]=myfinaldata[1:,:]\n",
    "    myfinaldata_1[-1,:]=myfinaldata[0,:]\n",
    "    myfinaldata_2=np.zeros(myfinaldata.shape)\n",
    "    myfinaldata_2[1:,:]=myfinaldata[:-1,:]\n",
    "    myfinaldata_2[0,:]=myfinaldata[-1,:]\n",
    "    \n",
    "    distance=np.arange(0.5*resolution, myfinaldata.shape[1]*resolution \n",
    "                       + 0.5*resolution, resolution)\n",
    "    distance=npm.repmat(distance,myfinaldata.shape[0],1)\n",
    "    distance=np.divide(np.multiply(distance,2*np.pi),360)\n",
    "    \n",
    "    myshear_1=(myfinaldata-myfinaldata_1)/(2*distance)*-(1)\n",
    "    myshear_2=(myfinaldata_2-myfinaldata)/(2*distance)*(-1)\n",
    "    myshear_3=(myfinaldata_2-myfinaldata_1)/(2*distance)*(-1)\n",
    "    \n",
    "    myshear_1_cor=shear_cor(myshear_1, distance, threshold, nyquist, min_size)\n",
    "        \n",
    "    myshear_2_cor=shear_cor(myshear_2, distance, threshold, nyquist, min_size)\n",
    "\n",
    "    myshear_3_cor=shear_cor(myshear_3, distance, threshold, nyquist, min_size)\n",
    "    \n",
    "    myshear_cor=np.nansum([myshear_2_cor,myshear_1_cor],axis=0)\n",
    "    myshear_cor[np.isnan(myfinaldata)==1]=myshear_3_cor[np.isnan(myfinaldata)==1]\n",
    "    mygateshear_cor=myshear_cor*distance\n",
    "    \n",
    "    return myshear_cor, mygateshear_cor\n",
    "\n",
    "# Identifies unfolding errors in derivative and corrects for them\n",
    "def shear_cor(myshear, distance, threshold, nyquist, min_size):\n",
    "    \"\"\"\n",
    "    Identifies unfolding errors in derivative and corrects for them\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    myshear : 2D array\n",
    "        input data.\n",
    "    distance : 2D array\n",
    "        azimuthal Cartesian distance between gates.\n",
    "    threshold : float\n",
    "        error identification threshold.\n",
    "    nyquist : float\n",
    "        correction interval (nyquist velocity).\n",
    "    min_size : int\n",
    "        minimum number of connected erroneous gates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    myshear_cor : 2D array\n",
    "        corrected data.\n",
    "\n",
    "    \"\"\"\n",
    "    ## function embedded in centered difference shear\n",
    "    ## eliminates anomalous shear in contiguous area\n",
    "    myshear_cor=(myshear*(2*distance))\n",
    "    thresh_1=(myshear*(2*distance))-threshold\n",
    "    thresh_2=(myshear*(2*distance))+threshold\n",
    "    \n",
    "    mybin_pos=np.zeros(myshear.shape)\n",
    "    mybin_pos[thresh_1>=0]=1\n",
    "    labels, n_groups=ndi.label(mybin_pos)\n",
    "    for n in range(1, n_groups):\n",
    "        size=len(np.where(labels==n)[0])\n",
    "        if size<min_size: labels[labels==n]=0\n",
    "        else: myshear_cor[labels==n] -= (2*nyquist)\n",
    "    \n",
    "    mybin_neg=np.zeros(myshear.shape)\n",
    "    mybin_neg[thresh_2<=0]=1\n",
    "    labels, n_groups=ndi.label(mybin_neg)\n",
    "    for n in range(1, n_groups):\n",
    "        size=len(np.where(labels==n)[0])\n",
    "        if size<min_size: labels[labels==n]=0\n",
    "        else: myshear_cor[labels==n] += (2*nyquist)\n",
    "    myshear_cor=myshear_cor/(2*distance)\n",
    "    return myshear_cor\n",
    "\n",
    "# azimuthal linear least squares derivative        \n",
    "def az_llsd(d_r, d_theta, u_k_r, u_k_thet, u_k, weights):\n",
    "    \"\"\"\n",
    "    azimuthal linear least squares derivative\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_r : array of same dimensions as data\n",
    "        radial distance.\n",
    "    d_theta : array of same dimensions as data\n",
    "        azimuthal distance.\n",
    "    u_k_r : array of same dimensions as data\n",
    "        data weighted radially.\n",
    "    u_k_thet : array of same dimensions as data\n",
    "        data weighted azimuthally.\n",
    "    u_k : array of same dimensions as data\n",
    "        data weighted uniformly.\n",
    "    weights : array of same dimensions as data\n",
    "        weights for convolution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    az_shear : array of same dimensions as data\n",
    "        azimuthal derivative of data.\n",
    "\n",
    "    \"\"\"\n",
    "    ##azimuthal linear least squares derivative\n",
    "    az_shear=( np.sum(weights * d_r * d_theta) * np.sum(weights * d_r * d_theta) * np.sum(weights) \\\n",
    "                + np.sum(weights * d_theta * d_theta) * np.sum(weights * d_r) * np.sum(weights * d_r) \\\n",
    "                + np.sum(weights * d_theta) * np.sum(weights * d_r * d_r) * np.sum(weights * d_theta) \\\n",
    "                - 2 * np.sum(weights * d_r * d_theta) * np.sum(weights * d_r) * np.sum(weights * d_theta) \\\n",
    "                - np.sum(weights * d_theta * d_theta) * np.sum(weights * d_r * d_r) * np.sum(weights)) ** (-1) \\\n",
    "                * ( u_k_r * (np.sum(weights * d_r * d_theta) * np.sum(weights) - np.sum(weights * d_theta) * np.sum(weights * d_r)) \\\n",
    "                + u_k_thet * ( - np.sum(weights * d_r * d_r) * np.sum(weights) + np.sum(weights * d_r) * np.sum(weights * d_r)) \\\n",
    "                + u_k * (np.sum(weights * d_r * d_r) * np.sum(weights * d_theta) - np.sum(weights * d_r) * np.sum(weights * d_r * d_theta)) )\n",
    "    return az_shear\n",
    "\n",
    "# radial linear least squares derivative\n",
    "def div_llsd(d_r, d_theta, u_k_r, u_k_thet, u_k, weights):\n",
    "    \"\"\"\n",
    "    radial linear least squares derivative\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_r : array of same dimensions as data\n",
    "        radial distance.\n",
    "    d_theta : array of same dimensions as data\n",
    "        azimuthal distance.\n",
    "    u_k_r : array of same dimensions as data\n",
    "        data weighted radially.\n",
    "    u_k_thet : array of same dimensions as data\n",
    "        data weighted azimuthally.\n",
    "    u_k : array of same dimensions as data\n",
    "        data weighted uniformly.\n",
    "    weights : array of same dimensions as data\n",
    "        weights for convolution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    div_shear : array of same dimensions as data\n",
    "        radial derivative of data.\n",
    "\n",
    "    \"\"\"\n",
    "    ##radial linear least squares derivative\n",
    "    div_shear= ( np.sum(weights * d_r * d_theta) * np.sum(weights * d_r * d_theta) * np.sum(weights) \\\n",
    "                + np.sum(weights * d_theta * d_theta) * np.sum(weights * d_r) * np.sum(weights * d_r) \\\n",
    "                + np.sum(weights * d_theta) * np.sum(weights * d_r * d_r) * np.sum(weights * d_theta) \\\n",
    "                - 2 * np.sum(weights * d_r * d_theta) * np.sum(weights * d_r) * np.sum(weights * d_theta) \\\n",
    "                - np.sum(weights * d_theta * d_theta) * np.sum(weights * d_r * d_r) * np.sum(weights)) ** (-1) \\\n",
    "                * ( u_k_r * (- np.sum(weights * d_theta * d_theta) * np.sum(weights) + np.sum(weights * d_theta) * np.sum(weights * d_theta)) \\\n",
    "                + u_k_thet * (np.sum(weights * d_r * d_theta) * np.sum(weights) - np.sum(weights * d_theta) * np.sum(weights * d_r)) \\\n",
    "                + u_k * ( - np.sum(weights * d_r * d_theta) * np.sum(weights * d_theta) + np.sum(weights * d_r) * np.sum(weights * d_theta * d_theta)) )\n",
    "    return div_shear\n",
    "\n",
    "# full linear least squares derivative\n",
    "def llsd(vel, az_min, az_max, w_k, r_k, resolution):\n",
    "    \"\"\"\n",
    "    full linear least squares derivative\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vel : 2D array\n",
    "        input data, polar data.\n",
    "    az_min : int\n",
    "        min. number of gates in azimuth.\n",
    "    az_max : int\n",
    "        max. number of gates in azimuth.\n",
    "    w_k : float\n",
    "        kernel width in azimuth (Cartesian).\n",
    "    r_k : float\n",
    "        kernel width in radial (Cartesian).\n",
    "    resolution : float\n",
    "        radial resolution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    az_shear : 2D array\n",
    "        azimuthal derivative.\n",
    "    div_shear : 2D array\n",
    "        radial derivative.\n",
    "\n",
    "    \"\"\"\n",
    "    ##complete linear least squares derivative\n",
    "    az_shear=np.zeros(vel.shape); az_shear[:]=np.nan\n",
    "    div_shear=np.zeros(vel.shape); div_shear[:]=np.nan\n",
    "    \n",
    "    distance=np.arange(0.5*resolution, vel.shape[1]*resolution \n",
    "                       + 0.5*resolution, resolution)\n",
    "    distance=npm.repmat(distance,vel.shape[0],1)\n",
    "    distance=np.divide(np.multiply(distance,2*np.pi),360)\n",
    "\n",
    "    r_h=int(np.floor(az_max/2))\n",
    "\t\n",
    "    for n2 in range(r_h,vel.shape[1]-r_h):\n",
    "        \n",
    "        az_w=int(np.round(w_k/distance[1,n2]));\n",
    "        if az_w%2 == 0: az_w+=1\n",
    "        if az_w>az_max: az_w=az_max\n",
    "        if az_w<az_min: az_w=az_min\n",
    "        az_r=int(np.floor(az_w/2))\n",
    "        \n",
    "        r_w= r_k/resolution;\n",
    "        if r_w%2 == 0: r_w+=1\n",
    "        r_w=int(r_w)\n",
    "        r_r=r_w*resolution\n",
    "        r_vec=np.arange(-r_r,r_r+resolution,resolution)\n",
    "        r_vec=np.expand_dims(r_vec,axis=0)\n",
    "        d_r=np.repeat(r_vec,az_w,axis=0)\n",
    "        \n",
    "        d_r=np.zeros([az_w,r_w])\n",
    "        for n2_2 in range(0,r_w):\n",
    "            d_r[:,n2_2]=-r_k*n2_2/(r_w-1)+r_k*0.5\n",
    "        rw_f=int(np.floor(r_w/2))\n",
    "\t    \n",
    "        d_r2=-copy.deepcopy(d_r); #print(d_r.shape,n2)\n",
    "        weights=np.ones([az_w,r_w])\n",
    "        d_theta=copy.deepcopy(distance[:az_w,n2-rw_f:n2+rw_f+1]); d_theta[az_r,:]=0\n",
    "        d_theta[:az_r,:]=-d_theta[:az_r,:];\n",
    "        d_thet=copy.deepcopy(d_theta); d_thet=-np.flip(d_thet,1)\n",
    "\n",
    "        u_k=convolve2d(vel[:,n2-rw_f:n2+rw_f+1],weights,mode='same',boundary='wrap')[:,1]\n",
    "        u_k_thet=convolve2d(vel[:,n2-rw_f:n2+rw_f+1],d_thet,mode='same',boundary='wrap')[:,1]\n",
    "        u_k_r=convolve2d(vel[:,n2-rw_f:n2+rw_f+1],d_r2,mode='same',boundary='wrap')[:,1]\n",
    "\n",
    "        az_shear[:,n2]= az_llsd(d_r, d_theta, u_k_r, u_k_thet, u_k, weights)\n",
    "        div_shear[:,n2]= div_llsd(d_r, d_theta, u_k_r, u_k_thet, u_k, weights)\n",
    "    return az_shear, div_shear\n",
    "\n",
    "# c_transform\n",
    "def c_transform(lon,lat):\n",
    "    \"\"\"\n",
    "    transforms arrays of lat/lon to chx/chy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon : float\n",
    "        longitude.\n",
    "    lat : float\n",
    "        latitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chx : float\n",
    "        chx in m.\n",
    "    chy : float\n",
    "        chy in m.\n",
    "\n",
    "    \"\"\"\n",
    "    converter = GPSConverter()\n",
    "    chx=np.zeros([len(lon)])\n",
    "    chy=np.zeros([len(lon)])\n",
    "    for n in range(len(lon)):\n",
    "        chx[n],chy[n],z=converter.WGS84toLV03(lat[n], lon[n], 0)\n",
    "    return chx,chy\n",
    "\n",
    "# transform_c \n",
    "def transform_c(chx,chy):\n",
    "    \"\"\"\n",
    "    transforms arrays of chx/chy to lat/lon\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    chx : float\n",
    "        chx in m.\n",
    "    chy : float\n",
    "        chy in m.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    lon : float\n",
    "        longitude.\n",
    "    lat : float\n",
    "        latitude.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    converter = GPSConverter()\n",
    "    lon=np.zeros([len(chx)])\n",
    "    lat=np.zeros([len(chy)])\n",
    "    for n in range(len(lon)):\n",
    "        lat[n], lon[n],z=converter.LV03toWGS84(chx[n],chy[n], 0)\n",
    "    return lon,lat\n",
    "\n",
    "\n",
    "\n",
    "# Radar locations\n",
    "if radar_station=='L':\n",
    "    radar_lat = 46.0401\n",
    "    radar_lon = 8.8334\n",
    "    radar_alt = 1627 \n",
    "if radar_station=='P':\n",
    "    radar_lat = 46.37083\n",
    "    radar_lon = 7.48694\n",
    "    radar_alt = 2927\n",
    "if radar_station=='W':\n",
    "    radar_lat = 46.832\n",
    "    radar_lon = 9.796\n",
    "    radar_alt = 2892 \n",
    "if radar_station=='A':\n",
    "    radar_lat = 47.2841\n",
    "    radar_lon = 8.5117\n",
    "    radar_alt = 938 \n",
    "if radar_station=='D':\n",
    "    radar_lat = 46.425676\n",
    "    radar_lon = 6.100092\n",
    "    radar_alt = 1670\n",
    "\n",
    "\n",
    "# Coordinates of cities Z체rich: 47.3769째 N, 8.5417째 E, Winterthur: 47.4980째 N, 8.7241째 E, St. Gallen: 47.4239째 N, 9.3748째 E\n",
    "z체rich_lat = 47.3769\n",
    "z체rich_lon = 8.5417\n",
    "winterthur_lat = 47.4980\n",
    "winterthur_lon = 8.7241\n",
    "stgallen_lat = 47.4239\n",
    "stgallen_lon = 9.3748\n",
    "\n",
    "# Load radar data\n",
    "path = '/scratch/mch/fackerma/orders/case_120721'\n",
    "file = glob.glob(path + '/ML/ML' + radar_station + '2119' + day + valid_time3 + '0U.00' + elevation_scan) # ML data \n",
    "file2 = glob.glob(path +'/DV/srn/data/tmp/mof/DV' + radar_station + '/DV' + radar_station + '2119' + day + valid_time3 + '7L.80' + elevation_scan) # Dealiased velocity\n",
    "file3 = glob.glob(path +'/HZC/HZC2119' + day + valid_time3 + 'VL.801') # Freezing level height composite\n",
    "#file4 = glob.glob(path +'/VAA/VA' + radar_station + '2119' + day + valid_time3 + '7U.019') # Vertical wind profile above radar\n",
    "file5 = glob.glob(path +'/BZC/BZC2119' + day + valid_time3 + 'VL.845') # POH\n",
    "file6 = glob.glob(path +'/MZC/MZC2119' + day + valid_time3 + 'VL.850') # MESH\n",
    "file7 = glob.glob(path +'/TRTC/CZC2119' + day + valid_time3 + '0T.rdt') # Thunderstorm radar tracking; or .rdt .trt\n",
    "file8 = glob.glob(path +'/CZC/CZC2119' + day + valid_time3 + 'VL.801') # Reflectivity composite\n",
    "file9 = glob.glob(path +'/LZC/LZC2119' + day + valid_time3 + 'VL.801') # VIL composite\n",
    "file10 = glob.glob(path +'/EZC/EZC2119' + day + valid_time3 + 'VL.820') # Echotops composite: 815, 820, 845, 850\n",
    "file11 = glob.glob(path +'/OZC/OZC2119' + day + valid_time3 + 'VL.830') # CAPPI composite, ranging from 810 to 980 in steps of 10\n",
    "file12 = glob.glob(path + '/dARC/ARC2119' + day + '0000FF.1440') # daily bias corrected rain accumulation\n",
    "file13 = glob.glob(path + '/dBZC/BZC2119' + day + '2400VL.845') # daily POH\n",
    "file14 = glob.glob(path + '/dRZC/RZC2119' + day + '2400VL.801') # daily Rain Rate\n",
    "file15 = glob.glob(path + '/dCZC/CZC2119' + day + '2400VL.801') # daily Max Echo\n",
    "\n",
    "\n",
    "# Read the data for the plots\n",
    "data = pyart.aux_io.read_metranet(file[0], reader='python')\n",
    "velocity = data.get_field(0, 'velocity').data\n",
    "reflectivity = data.get_field(0, 'reflectivity').data\n",
    "\n",
    "dv_data = pyart.aux_io.read_file_py(file2[0], physic_value=False)\n",
    "dv_digital = dv_data.data\n",
    "dv_header = dv_data.header\n",
    "nyq = float(dv_header['nyquist'])\n",
    "dv_velocity = transform_from_digital(dv_digital, nyq)\n",
    "\n",
    "hzc_data = radlib.read_file(file3[0],physic_value=True)\n",
    "hzc=hzc_data.data\n",
    "\n",
    "dARC_data = radlib.read_file(file12[0],physic_value=True)\n",
    "dARC=dARC_data.data\n",
    "\n",
    "dBZC_data = radlib.read_file(file13[0],physic_value=True)\n",
    "dBZC=dBZC_data.data\n",
    "\n",
    "dRZC_data = radlib.read_file(file14[0],physic_value=True)\n",
    "dRZC=dRZC_data.data\n",
    "\n",
    "dCZC_data = radlib.read_file(file15[0],physic_value=True)\n",
    "dCZC=dCZC_data.data\n",
    "\n",
    "diff_reflectivity = data.get_field(0, 'differential_reflectivity').data\n",
    "\n",
    "diff_phase = data.get_field(0, 'uncorrected_differential_phase').data\n",
    "\n",
    "cc_ratio = data.get_field(0, 'uncorrected_cross_correlation_ratio').data\n",
    "\n",
    "mzc_data = radlib.read_file(file6[0],physic_value=True)\n",
    "mzc=mzc_data.data\n",
    "\n",
    "bzc_data = radlib.read_file(file5[0],physic_value=True)\n",
    "bzc=bzc_data.data\n",
    "\n",
    "specw = data.get_field(0, 'spectrum_width').data\n",
    "\n",
    "czc_data = radlib.read_file(file8[0],physic_value=True)\n",
    "czc=czc_data.data\n",
    "\n",
    "lzc_data = radlib.read_file(file9[0],physic_value=True)\n",
    "lzc=lzc_data.data\n",
    "\n",
    "ezc_data = radlib.read_file(file10[0],physic_value=True)\n",
    "ezc=ezc_data.data\n",
    "\n",
    "ozc_data = radlib.read_file(file11[0],physic_value=True)\n",
    "ozc=ozc_data.data\n",
    "\n",
    "path_trtc = {\"lomdata\": \"/scratch/mch/fackerma/orders/case_120721/\"}  # Replace with your actual path\n",
    "trtc = read_TRT(path_trtc, ttime=valid_time3)\n",
    "\n",
    "#vad = read_VAD(file4[0])\n",
    "\n",
    "# Convert echotop18 from km to meters\n",
    "ezc_m = ezc * 1000\n",
    "# Compute the wind gust estimator 'wge' (Trefalt 2017)\n",
    "wge = np.sqrt((-3.1 * 10**-6 * (ezc**2)) + (20.6 * lzc))\n",
    "\n",
    "\n",
    "resolution = 0.5\n",
    "range_max = reflectivity.shape[1] * resolution\n",
    "azimuths = np.linspace(0, 360, reflectivity.shape[0])\n",
    "ranges = np.arange(0, range_max, resolution)\n",
    "\n",
    "# Own KDP calculation\n",
    "smoothed_diff_phase = gaussian_filter1d(diff_phase, sigma=2, axis=1) \n",
    "Kdp = np.gradient(smoothed_diff_phase, ranges, axis=1)\n",
    "\n",
    "# KDP Vulpiani Method\n",
    "#Kdp = pyart.retrieve.kdp_vulpiani(data, psidp_field='uncorrected_differential_phase', band='C', parallel=True)\n",
    "\n",
    "# Radial llsd_vel[1] and azimuthal llsd_vel[0] shear\n",
    "llsd_vel = llsd(vel=dv_velocity, az_min=3, az_max=90, w_k=2, r_k=1.5, resolution=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transform radar polar coordinates to lat/lon\n",
    "lats, lons = radar_to_latlon(radar_lat, radar_lon, ranges, azimuths)\n",
    "\n",
    "# Define the Swiss grid (values based on metadata)\n",
    "chx = np.arange(255000, 255000 + 710 * 1000 + 1, 1000)\n",
    "chy = sorted(np.arange(-160000, -160000 + 640 * 1000 + 1, 1000), reverse=True)\n",
    "X, Y = np.meshgrid(chx, chy)\n",
    "# Initialize transformer for Swiss grid \n",
    "transformer = Transformer.from_crs(21781, 3035, always_xy=True)\n",
    "\n",
    "#lons,lats = transformer.transform(X, Y)\n",
    "clons, clats = transformer.transform(X, Y)\n",
    "#lons, lats = transformer.transform(X, Y)\n",
    "\n",
    "\n",
    "# Define color steps for Reflectivity and Velocity/Dealiased Velocity\n",
    "czc_levels = np.arange(-5, 65, 5)  # Steps of 2 for Reflectivity\n",
    "reflectivity_levels = np.arange(-5, 65, 5)  # Steps of 2 for Reflectivity\n",
    "velocity_levels = np.arange(-25, 26, 5)  # Steps of 1 for Velocity and Dealiased Velocity\n",
    "hzc_levels = np.arange(1, 10, 1)\n",
    "diff_reflectivity_levels = np.arange(-7,9,2)\n",
    "diff_phase_levels = np.arange(-70,90,20)\n",
    "cc_ratio_levels = np.arange(0.7,1,0.05)\n",
    "mzc_levels = np.arange(0,5.5,0.5)\n",
    "bzc_levels = np.arange(0,101,10)\n",
    "specw_levels = np.arange(0,7,1)\n",
    "Kdp_levels = np.arange(0,5.5,0.5)\n",
    "lzc_levels = np.arange(2.5,25,2.5)\n",
    "ezc_levels = np.arange(2,16,2)\n",
    "wge_levels = np.arange(2,20,2)\n",
    "az_shear_levels = np.arange(-10,12,2)\n",
    "div_shear_levels = np.arange(-10,12,2)\n",
    "# Create boundary norms\n",
    "czc_norm = BoundaryNorm(boundaries=czc_levels, ncolors=plt.cm.inferno.N, clip=True)\n",
    "reflectivity_norm = BoundaryNorm(boundaries=reflectivity_levels, ncolors=plt.cm.inferno.N, clip=True)\n",
    "velocity_norm = BoundaryNorm(boundaries=velocity_levels, ncolors=256, clip=True)\n",
    "hzc_norm = BoundaryNorm(boundaries=hzc_levels, ncolors=256, clip=True)\n",
    "diff_reflectivity_norm = BoundaryNorm(boundaries=diff_reflectivity_levels, ncolors=256, clip=True)\n",
    "diff_phase_norm = BoundaryNorm(boundaries=diff_phase_levels, ncolors=256, clip=True)\n",
    "cc_ratio_norm = BoundaryNorm(boundaries=cc_ratio_levels, ncolors=256, clip=True)\n",
    "mzc_norm = BoundaryNorm(boundaries=mzc_levels, ncolors=256, clip=True)\n",
    "bzc_norm = BoundaryNorm(boundaries=bzc_levels, ncolors=256, clip=True)\n",
    "specw_norm = BoundaryNorm(boundaries=specw_levels, ncolors=256, clip=True)\n",
    "Kdp_norm = BoundaryNorm(boundaries=Kdp_levels, ncolors=256, clip=True)\n",
    "lzc_norm = BoundaryNorm(boundaries=lzc_levels, ncolors=256, clip=True)\n",
    "ezc_norm = BoundaryNorm(boundaries=ezc_levels, ncolors=256, clip=True)\n",
    "wge_norm = BoundaryNorm(boundaries=wge_levels, ncolors=256, clip=True)\n",
    "az_shear_norm = BoundaryNorm(boundaries=az_shear_levels, ncolors=256, clip=True)\n",
    "div_shear_norm = BoundaryNorm(boundaries=div_shear_levels, ncolors=256, clip=True)\n",
    "\n",
    "cmap_czc = plt.cm.inferno\n",
    "cmap_velocity = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\", \"red\"], N=256)\n",
    "cmap_hzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", \"dodgerblue\", \"midnightblue\"], N=256)\n",
    "cmap_diff_reflectivity = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\",\"red\"], N=256)\n",
    "cmap_diff_phase = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\",\"red\"], N=256)\n",
    "cmap_cc_ratio = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_Kdp = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_bzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\",\"yellow\", \"red\"], N=256)\n",
    "cmap_specw = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_lzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\", \"cyan\", \"purple\"], N=256)\n",
    "cmap_ezc = plt.cm.Blues\n",
    "cmap_wge = plt.cm.magma\n",
    "cmap_vad = plt.cm.Accent\n",
    "cmap_az_shear = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"aqua\",\"blue\", \"black\", \"red\",\"yellow\"], N=256)\n",
    "cmap_div_shear = cmap_az_shear\n",
    "\n",
    "# Assess rhi files\n",
    "#files_rhi = sorted(glob.glob(path + '/MLA/MLA23236' + valid_time3 + '*')) # Read all elevations for rhi\n",
    "#for i,f in enumerate(files_rhi):\n",
    " #   radar = pyart.aux_io.read_metranet(f)\n",
    " #   \n",
    " #   if i == 0:\n",
    " #       radar_merged = radar\n",
    " #   else:\n",
    " #       radar_merged = pyart.util.join_radar(radar_merged, \n",
    "#                                       radar)\n",
    "#corr_vel = pyart.correct.dealias_region_based(radar_merged)\n",
    "#radar_merged.add_field('corrected_velocity', corr_vel)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variable plot\n",
    "projection = ccrs.epsg(3035)\n",
    "# Create figure with three subplots (Reflectivity, Velocity, and Dealiased Velocity)\n",
    "fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(24,24), subplot_kw={'projection': projection})\n",
    "\n",
    "# Set background to black for all subplots\n",
    "for row in axs:  # axs is a 2D array, so iterate through rows\n",
    "    for ax in row:  # Iterate through each subplot in the row\n",
    "        fig.patch.set_facecolor('black')  # Set figure background\n",
    "        ax.set_facecolor('black')  # Set axis background\n",
    "\n",
    "\n",
    "# Plot Reflectivity composite\n",
    "cmap_czc = plt.cm.inferno\n",
    "cmap_czc.set_bad(color='grey')\n",
    "p1 = axs[0,0].pcolormesh(clons, clats, czc, vmin=0, vmax=55, \n",
    "                   cmap=cmap_czc, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar1 = plt.colorbar(p1, ax=axs[0,0], extend='both', cmap=cmap_czc, norm=czc_norm, boundaries=czc_levels, ticks=czc_levels\n",
    "                     )\n",
    "cbar1.outline.set_edgecolor('white')\n",
    "cbar1.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar1.ax.axes, 'yticklabels'), color='white')\n",
    "axs[0,0].set_title('Z Composite [dBZ]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Dealiased Velocity\n",
    "cmap_velocity = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\", \"red\"], N=256)\n",
    "cmap_velocity.set_bad(color='black')\n",
    "# Assuming lons and lats are 1D arrays\n",
    "p2 = axs[0,1].pcolormesh(lons, lats, dv_velocity, cmap=cmap_velocity, norm=velocity_norm, transform=ccrs.PlateCarree())\n",
    "cbar2 = plt.colorbar(p2, ax=axs[0,1], cmap=cmap_velocity, extend='both', boundaries=velocity_levels, ticks=velocity_levels)\n",
    "cbar2.outline.set_edgecolor('white')\n",
    "cbar2.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar2.ax.axes, 'yticklabels'), color='white')\n",
    "axs[0,1].set_title('Velocity [m s뼘]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Freezing level height\n",
    "# Mask values of freezing level height that are 0 or lower\n",
    "hzc_masked = np.ma.masked_less_equal(hzc, 0)\n",
    "# Define a custom colormap, setting the under value (for masked/low values) to black\n",
    "cmap_hzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", \"dodgerblue\", \"midnightblue\"], N=256)\n",
    "#cmap_hzc.set_under('black')  # Black for values 0 or lower\n",
    "cmap_hzc.set_bad(color='black')  # Black for invalid data\n",
    "# Plot the freezing level height with the masked values\n",
    "p3 = axs[0,2].pcolormesh(clons, clats, hzc_masked, vmin=0, vmax=12, \n",
    "                         cmap=cmap_hzc, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar3 = plt.colorbar(p3, ax=axs[0,2], extend='both', cmap=cmap_hzc, boundaries=hzc_levels, ticks=hzc_levels)\n",
    "cbar3.outline.set_edgecolor('white')\n",
    "cbar3.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar3.ax.axes, 'yticklabels'), color='white')\n",
    "axs[0,2].set_title('Freezing Level Height Composite [km]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Differential Reflectivity\n",
    "cmap_diff_reflectivity = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\",\"red\"], N=256)\n",
    "cmap_diff_reflectivity.set_bad(color='black')\n",
    "p4 = axs[1,0].pcolormesh(lons, lats, diff_reflectivity, cmap=cmap_diff_reflectivity, norm=diff_reflectivity_norm, \n",
    "                         transform=ccrs.PlateCarree())\n",
    "cbar4 = plt.colorbar(p4, ax=axs[1,0], cmap=cmap_diff_reflectivity, extend='both', boundaries=diff_reflectivity_levels, ticks=diff_reflectivity_levels\n",
    "                     )\n",
    "cbar4.outline.set_edgecolor('white')\n",
    "cbar4.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar4.ax.axes, 'yticklabels'), color='white')\n",
    "axs[1,0].set_title('Zdr [dB]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Differential Phase\n",
    "cmap_diff_phase = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"blue\", \"white\",\"red\"], N=256)\n",
    "cmap_diff_phase.set_bad(color='black')\n",
    "p5 = axs[1,1].pcolormesh(lons, lats, diff_phase, cmap=cmap_diff_phase, norm=diff_phase_norm, \n",
    "                         transform=ccrs.PlateCarree())\n",
    "cbar5 = plt.colorbar(p5, ax=axs[1,1], cmap=cmap_diff_phase, extend='both', boundaries=diff_phase_levels, ticks=diff_phase_levels\n",
    "                     )\n",
    "cbar5.outline.set_edgecolor('white')\n",
    "cbar5.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar5.ax.axes, 'yticklabels'), color='white')\n",
    "axs[1,1].set_title('Uncorrected 過DP [째]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot CC ratio\n",
    "cmap_cc_ratio = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_cc_ratio.set_bad(color='black')\n",
    "p6 = axs[1,2].pcolormesh(lons, lats, cc_ratio, cmap=cmap_cc_ratio, norm=cc_ratio_norm, \n",
    "                         transform=ccrs.PlateCarree())\n",
    "cbar6 = plt.colorbar(p6, ax=axs[1,2], cmap=cmap_cc_ratio, extend='both', boundaries=cc_ratio_levels, ticks=cc_ratio_levels\n",
    "                     )\n",
    "cbar6.outline.set_edgecolor('white')\n",
    "cbar6.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar6.ax.axes, 'yticklabels'), color='white')\n",
    "axs[1,2].set_title('Uncorrected hv', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Kdp\n",
    "cmap_Kdp = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_Kdp.set_bad(color='black')\n",
    "p7 = axs[2,0].pcolormesh(lons, lats, Kdp, norm=Kdp_norm,\n",
    "                   cmap=cmap_Kdp, transform=ccrs.PlateCarree())\n",
    "# Add a colorbar\n",
    "cbar7 = plt.colorbar(p7, ax=axs[2,0], extend='both', cmap=cmap_Kdp, boundaries=Kdp_levels, ticks=Kdp_levels\n",
    "                     )\n",
    "cbar7.outline.set_edgecolor('white')\n",
    "cbar7.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar7.ax.axes, 'yticklabels'), color='white')\n",
    "axs[2,0].set_title('Kdp [째 km뼘]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot POH\n",
    "cmap_bzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\",\"yellow\", \"red\"], N=256)\n",
    "cmap_bzc.set_bad(color='black')\n",
    "p8 = axs[2,1].pcolormesh(clons, clats, bzc, norm=bzc_norm,\n",
    "                   cmap=cmap_bzc, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar8 = plt.colorbar(p8, ax=axs[2,1], extend='both', cmap=cmap_bzc, boundaries=bzc_levels, ticks=bzc_levels\n",
    "                     )\n",
    "cbar8.outline.set_edgecolor('white')\n",
    "cbar8.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar8.ax.axes, 'yticklabels'), color='white')\n",
    "axs[2,1].set_title('POH Composite [%]', color='white', loc='right')\n",
    "\n",
    "\n",
    "# Plot Spectrum Width\n",
    "cmap_specw = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"darkblue\", \"lightblue\",\"yellow\",\"orange\",\"red\"], N=256)\n",
    "cmap_specw.set_bad(color='black')\n",
    "p9 = axs[2,2].pcolormesh(lons, lats, specw, cmap=cmap_specw, norm=specw_norm, \n",
    "                         transform=ccrs.PlateCarree())\n",
    "cbar9 = plt.colorbar(p9, ax=axs[2,2], cmap=cmap_specw, extend='both', boundaries=specw_levels, ticks=specw_levels\n",
    "                     )\n",
    "cbar9.outline.set_edgecolor('white')\n",
    "cbar9.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar9.ax.axes, 'yticklabels'), color='white')\n",
    "axs[2,2].set_title('Spectrum Width [m s뼘]', color='white', loc='right')\n",
    "\n",
    "# Plot VIL composite\n",
    "#lzc = np.ma.masked_less_equal(lzc, 0.1)\n",
    "cmap_lzc = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\", \"cyan\", \"purple\"#, \"red\"\n",
    "                                                             ], N=256)\n",
    "cmap_lzc.set_bad(color='black')\n",
    "p10 = axs[3,0].pcolormesh(clons, clats, lzc, vmin=1, vmax=22.5, \n",
    "                   cmap=cmap_lzc, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar10 = plt.colorbar(p10, ax=axs[3,0], extend='both', cmap=cmap_lzc, norm=lzc_norm, boundaries=lzc_levels, ticks=lzc_levels\n",
    "                     )\n",
    "cbar10.outline.set_edgecolor('white')\n",
    "cbar10.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar10.ax.axes, 'yticklabels'), color='white')\n",
    "axs[3,0].set_title('VIL Composite [kg m뼘]', color='white', loc='right')\n",
    "\n",
    "# Plot Echotop 20 composite\n",
    "# Set a mask\n",
    "ezc = np.ma.masked_less_equal(ezc, 0)\n",
    "cmap_ezc = plt.cm.Blues\n",
    "cmap_ezc.set_bad(color='black')\n",
    "p11 = axs[3,1].pcolormesh(clons, clats, ezc, vmin=0, vmax=14,  \n",
    "                   cmap=cmap_ezc, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar11 = plt.colorbar(p11, ax=axs[3,1], extend='both', cmap=cmap_ezc, norm=ezc_norm, boundaries=ezc_levels, ticks=ezc_levels\n",
    "                     )\n",
    "cbar11.outline.set_edgecolor('white')\n",
    "cbar11.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar11.ax.axes, 'yticklabels'), color='white')\n",
    "axs[3,1].set_title('Echotop20 Composite [km]', color='white', loc='right')\n",
    "\n",
    "# Plot wge composite\n",
    "# Set a mask\n",
    "wge = np.ma.masked_less_equal(wge, 0)\n",
    "cmap_wge = plt.cm.magma\n",
    "cmap_wge.set_bad(color='black')\n",
    "p12 = axs[3,2].pcolormesh(clons, clats, wge, vmax=18, \n",
    "                   cmap=cmap_wge, transform=projection)\n",
    "# Add a colorbar\n",
    "cbar12 = plt.colorbar(p12, ax=axs[3,2], extend='both', cmap=cmap_wge, norm=wge_norm, boundaries=wge_levels, ticks=wge_levels\n",
    "                     )\n",
    "cbar12.outline.set_edgecolor('white')\n",
    "cbar12.ax.yaxis.set_tick_params(color='white')\n",
    "plt.setp(plt.getp(cbar12.ax.axes, 'yticklabels'), color='white')\n",
    "axs[3,2].set_title('Max. Downdraft Velocity w [m s뼘]', color='white', loc='right')\n",
    "\n",
    "# (Plotting of wind barbs and other features remains the same)\n",
    "# Add Radar, Geneva, and Lausanne locations to all plots\n",
    "for row in axs:\n",
    "    for ax in row:\n",
    "            #ax.plot(radar_lon, radar_lat, marker='x', color='yellow', markersize=12, transform=ccrs.PlateCarree())  # Radar location\n",
    "        ax.plot(radar_lon, radar_lat, marker='x', color='yellow', markersize=12, transform=ccrs.PlateCarree(),\n",
    "        path_effects=[path_effects.withStroke(linewidth=2, foreground='black')])\n",
    "        ax.plot(z체rich_lon, z체rich_lat, marker='o', color='white', markersize=8, markeredgecolor='black', markeredgewidth=2, transform=ccrs.PlateCarree()) \n",
    "        ax.plot(winterthur_lon, winterthur_lat, marker='o', color='white', markersize=8, markeredgecolor='black', markeredgewidth=2, transform=ccrs.PlateCarree()) \n",
    "        ax.plot(stgallen_lon, stgallen_lat, marker='o', color='white', markersize=8, markeredgecolor='black', markeredgewidth=2, transform=ccrs.PlateCarree())  \n",
    "        ax.set_extent([8.3, 9.7 , 47, 47.9], crs=ccrs.PlateCarree())\n",
    "         # Add borders, coastlines, and lakes with custom contour lines\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='black', linestyle='-', alpha=0.8, linewidth=2)\n",
    "        ax.add_feature(cfeature.COASTLINE, edgecolor='black', alpha=0.8, linewidth=2)\n",
    "        ax.add_feature(cfeature.LAKES, edgecolor='black', facecolor='none', alpha=0.8, linewidth=2)\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='white', linestyle='-', alpha=0.7)\n",
    "        ax.add_feature(cfeature.COASTLINE, edgecolor='white', alpha=0.7)\n",
    "        ax.add_feature(cfeature.LAKES, edgecolor='white', facecolor='none', alpha=0.7)\n",
    "        # Add city names with a black outline for visibility\n",
    "        z체rich_text = ax.text(z체rich_lon + 0.04, z체rich_lat, 'Zurich', color='white', fontsize=14, transform=ccrs.PlateCarree())\n",
    "        winterthur_text = ax.text(winterthur_lon + 0.04, winterthur_lat, 'Winterthur', color='white', fontsize=14, transform=ccrs.PlateCarree())\n",
    "        stgallen_text = ax.text(stgallen_lon + 0.04, stgallen_lat, 'St. Gallen', color='white', fontsize=14, transform=ccrs.PlateCarree())\n",
    "        z체rich_text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'), path_effects.Normal()])\n",
    "        winterthur_text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'), path_effects.Normal()])\n",
    "        stgallen_text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'), path_effects.Normal()])\n",
    "\n",
    "\n",
    "    \n",
    "# Data import, assimilation\n",
    "file_path = '/scratch/mch/fackerma/orders/case_120721/stations/20210712.csv'\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    station_data = file.readlines()  # Read all lines into a list\n",
    "\n",
    "# Import stations readme\n",
    "file_path = '/users/fackerma/newproject1/stations_readme.csv'\n",
    "\n",
    "# Open and read the file as plain text\n",
    "try:\n",
    "    with open(file_path, 'r') as stations:\n",
    "        stations = stations.readlines()  # Read all lines into a list\n",
    "    #for line in content[:10]:  # Print the first 10 lines for inspection\n",
    "        #print(line.strip())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n",
    "\n",
    "# Parse the station metadata to create a dictionary mapping station ID to coordinates and altitude\n",
    "station_info = {}\n",
    "\n",
    "# Extract the relevant station data from 'stations' (first 158 rows)\n",
    "for line in stations[0:0+158]:  # Starts from line 5, inclusive\n",
    "    parts = line.strip().split(\"\\t\")\n",
    "    station_id = parts[0].strip()  # First column: Station ID\n",
    "    \n",
    "    # Extract coordinates (last column)\n",
    "    coordinates = parts[-1].strip()  \n",
    "    x, y = map(int, coordinates.split(\"/\"))  # Split the coordinates into x and y\n",
    "\n",
    "    # Extract altitude (using regex to find the number before \"m a.s.l.\")\n",
    "    altitude_match = re.search(r'(\\d+)\\s*m\\s*a\\.s\\.l\\.', parts[1])\n",
    "    altitude = int(altitude_match.group(1)) if altitude_match else None  # Default to None if no altitude found\n",
    "    \n",
    "    station_info[station_id] = (x, y, altitude)\n",
    "\n",
    "# Add Swiss coordinates and altitude to 'station_data'\n",
    "updated_station_data = []\n",
    "\n",
    "# Add headers for clarity\n",
    "header = station_data[0].strip() + \"   X_COORD   Y_COORD   ALTITUDE\\n\"\n",
    "updated_station_data.append(header)\n",
    "\n",
    "for line in station_data[1:]:  # Skip the header\n",
    "    parts = line.strip().split()\n",
    "    station_id = parts[0].strip()  # First column: Station ID\n",
    "    \n",
    "    # Lookup coordinates and altitude for the station\n",
    "    x, y, altitude = station_info.get(station_id, (None, None, None))\n",
    "    \n",
    "    if x is not None and y is not None and altitude is not None:\n",
    "        # Append the coordinates and altitude as new columns\n",
    "        updated_line = line.strip() + f\"   {x}   {y}   {altitude}\\n\"\n",
    "    else:\n",
    "        # In case no coordinates or altitude are found (unlikely here), keep it unchanged\n",
    "        updated_line = line.strip() + \"   N/A   N/A   N/A\\n\"\n",
    "    \n",
    "    updated_station_data.append(updated_line)\n",
    "\n",
    "# Assuming converter.LV03toWGS84() function is defined, and it converts LV03 to WGS84\n",
    "# Function to convert LV03 to WGS84 (assuming this is already defined)\n",
    "# Example: converter.LV03toWGS84(x, y, altitude) returns [latitude, longitude, altitude]\n",
    "\n",
    "# Iterate over each row in updated_station_data (skip the header)\n",
    "for i, line in enumerate(updated_station_data[1:], start=1):\n",
    "    parts = line.strip().split()\n",
    "    \n",
    "    # Extract the X_COORD, Y_COORD, and ALTITUDE for the current station\n",
    "    x_coord = int(parts[-3])  # X_COORD is the second last column\n",
    "    y_coord = int(parts[-2])  # Y_COORD is the last column before altitude\n",
    "    altitude = int(parts[-1])  # ALTITUDE is the last column in the row\n",
    "    \n",
    "    # Convert LV03 (x_coord, y_coord, altitude) to WGS84 (latitude, longitude, altitude)\n",
    "    wgs84 = converter.LV03toWGS84(x_coord, y_coord, altitude)\n",
    "    \n",
    "    # Append the WGS84 values as new columns: latitude, longitude, altitude\n",
    "    updated_station_data[i] = line.strip() + f\"   {wgs84[0]}   {wgs84[1]}   {wgs84[2]}\"\n",
    "    \n",
    "# Add headers for latitude, longitude, and altitude to the header row\n",
    "header = updated_station_data[0].strip() + \"   LATITUDE   LONGITUDE   ALTITUDE_NEW\"\n",
    "updated_station_data[0] = header\n",
    "\n",
    "# Data assimilation\n",
    "# Extract the headers and rows\n",
    "headers = updated_station_data[0].split()\n",
    "data = [line.split() for line in updated_station_data[1:]]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Convert relevant columns to numeric (e.g., the wind gust column '101')\n",
    "df['101'] = pd.to_numeric(df['101'], errors='coerce')\n",
    "df['197'] = pd.to_numeric(df['197'], errors='coerce')\n",
    "df['UTC'] = (df['JAHR'].astype(str) +\n",
    "                      df['MO'].astype(str).str.zfill(2) +\n",
    "                      df['TG'].astype(str).str.zfill(2) +\n",
    "                      df['HH'].astype(str).str.zfill(2) +\n",
    "                      df['MM'].astype(str).str.zfill(2))\n",
    "\n",
    "# Filter the data for the timestamp closest to 14:30 UTC (1430)\n",
    "target_time = '202107' + calendar_day + valid_time3\n",
    "filtered_df = df[df['UTC'] == target_time]\n",
    "# Filter out rows where the '101' value is greater than 200\n",
    "filtered_df = filtered_df[filtered_df['101'] <= 200]\n",
    "\n",
    "# Extract necessary columns (station ID, wind speed, wind direction)\n",
    "wind_speeds = filtered_df['101'].values\n",
    "wind_directions = filtered_df['197'].values\n",
    "station_ids = filtered_df['STA'].values\n",
    "\n",
    "filtered_df['LONGITUDE'] = pd.to_numeric(filtered_df['LONGITUDE'], errors='coerce')\n",
    "filtered_df['LATITUDE'] = pd.to_numeric(filtered_df['LATITUDE'], errors='coerce')\n",
    "filtered_df['101'] = pd.to_numeric(filtered_df['101'], errors='coerce')\n",
    "filtered_df['197'] = pd.to_numeric(filtered_df['197'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid data\n",
    "filtered_df = filtered_df.dropna(subset=['LONGITUDE', 'LATITUDE', '101', '197'])\n",
    "\n",
    "\n",
    "# Select a specific subplot for the wind barbs (e.g., the first subplot)\n",
    "#ax = axs[0:3, 0:2]  # Adjust the index based on your layout preference\n",
    "\n",
    "# Iterate over rows in the filtered dataframe\n",
    "for _, row in filtered_df.iterrows():\n",
    "    try:\n",
    "        # Extract values directly without wrapping them in float or np.array\n",
    "        longitude = row['LONGITUDE']\n",
    "        latitude = row['LATITUDE']\n",
    "        speed = row['101']  # Wind speed\n",
    "        direction = row['197']  # Wind direction\n",
    "\n",
    "        # Ensure the values are 1-dimensional arrays\n",
    "        longitude = np.array([longitude])  # Wrap as 1D array\n",
    "        latitude = np.array([latitude])    # Wrap as 1D array\n",
    "        speed = np.array([speed])\n",
    "        direction = np.array([direction])\n",
    "        \n",
    "        # Convert to wind components\n",
    "        u = -speed * np.sin(np.radians(direction)) * 3.6\n",
    "        v = -speed * np.cos(np.radians(direction)) * 3.6\n",
    "        \n",
    "        for row in axs:\n",
    "            for ax in row:\n",
    "        # Add a single wind barb\n",
    "                ax.barbs(longitude, latitude, u, v, transform=ccrs.PlateCarree(), color='black', length=6, linewidth=1.5)\n",
    "                ax.barbs(longitude, latitude, u, v, transform=ccrs.PlateCarree(), color='lime', length=6, linewidth=1)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping row due to error: {e}\")\n",
    "\n",
    "\n",
    "# Set main title\n",
    "plt.suptitle(valid_time3 + ' UTC, ' + radar_name + ' elevation scan: ' + elevation_scan + ', Barbs: 10 min max s뼘 gust speed [km h뼘]', color='white', fontsize=16, x=0.5)\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig(\"/users/fackerma/newproject1/figures/fourth_case/\" + radar_station + valid_time3 + \"_\" + elevation_scan + \"_all_variables.png\", facecolor='black', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
